#!/usr/bin/env python3
"""
æ¸¬è©¦ HinaAdaptive èƒŒæ™¯æ­£å‰‡åŒ–ä¸åŒæ¨¡å¼çš„æ€§èƒ½
"""

import torch
import torch.nn as nn
import time
import sys
import os

# æ·»åŠ  library è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from library.hina_adaptive import HinaAdaptive


def create_test_model():
    """å‰µå»ºä¸€å€‹ç°¡å–®çš„æ¸¬è©¦æ¨¡å‹"""
    model = nn.Sequential(
        nn.Linear(128, 256),
        nn.ReLU(),
        nn.Linear(256, 512),
        nn.ReLU(),
        nn.Linear(512, 256),
        nn.ReLU(),
        nn.Linear(256, 10)
    )
    return model


def test_background_regularization_mode(mode: str, num_steps: int = 100):
    """æ¸¬è©¦æŒ‡å®šæ¨¡å¼çš„èƒŒæ™¯æ­£å‰‡åŒ–æ€§èƒ½"""
    print(f"\n=== æ¸¬è©¦ {mode} æ¨¡å¼ ===")

    # å‰µå»ºæ¨¡å‹å’Œå„ªåŒ–å™¨
    model = create_test_model()
    if torch.cuda.is_available():
        model = model.cuda()

    optimizer = HinaAdaptive(
        model.parameters(),
        lr=1e-3,
        background_regularization=True,
        background_regularization_mode=mode
    )

    # å‰µå»ºå‡æ•¸æ“š
    batch_size = 32
    input_size = 128
    if torch.cuda.is_available():
        data = torch.randn(batch_size, input_size).cuda()
        target = torch.randint(0, 10, (batch_size,)).cuda()
    else:
        data = torch.randn(batch_size, input_size)
        target = torch.randint(0, 10, (batch_size,))

    criterion = nn.CrossEntropyLoss()

    # è¨ˆæ™‚æ¸¬è©¦
    start_time = time.time()

    for step in range(num_steps):
        optimizer.zero_grad()

        # å‰å‘å‚³æ’­
        output = model(data)
        loss = criterion(output, target)

        # åå‘å‚³æ’­
        loss.backward()

        # å„ªåŒ–å™¨æ­¥é©Ÿ
        optimizer.step()

        if (step + 1) % 20 == 0:
            print(f"Step {step + 1}/{num_steps}, Loss: {loss.item():.4f}")

    end_time = time.time()
    total_time = end_time - start_time

    print(f"ç¸½è€—æ™‚: {total_time:.2f} ç§’")
    print(f"å¹³å‡æ¯æ­¥è€—æ™‚: {total_time/num_steps*1000:.2f} ms")

    return {'total_time': total_time, 'avg_time_per_step': total_time/num_steps}


def main():
    """ä¸»å‡½æ•¸"""
    print("HinaAdaptive èƒŒæ™¯æ­£å‰‡åŒ–æ¨¡å¼æ€§èƒ½æ¸¬è©¦")
    print("=" * 50)

    device_info = "CUDA" if torch.cuda.is_available() else "CPU"
    print(f"è¨­å‚™: {device_info}")

    # æ¸¬è©¦ä¸åŒæ¨¡å¼
    modes = ["simple", "fast"]
    results = {}

    for mode in modes:
        try:
            stats = test_background_regularization_mode(mode, num_steps=50)
            results[mode] = stats
        except Exception as e:
            print(f"æ¸¬è©¦ {mode} æ¨¡å¼æ™‚å‡ºéŒ¯: {e}")
            continue

    # æ¯”è¼ƒçµæœ
    print("\n" + "=" * 50)
    print("æ€§èƒ½æ¯”è¼ƒæ‘˜è¦")
    print("=" * 50)

    for mode, stats in results.items():
        print(f"\n{mode.upper()} æ¨¡å¼:")
        print(f"  ç¸½è€—æ™‚: {stats['total_time']:.2f} ç§’")
        print(f"  å¹³å‡æ¯æ­¥è€—æ™‚: {stats['avg_time_per_step']*1000:.2f} ms")

    # æ€§èƒ½å»ºè­°
    if len(results) > 1:
        simple_time = results.get('simple', {}).get('avg_time_per_step', float('inf'))
        fast_time = results.get('fast', {}).get('avg_time_per_step', float('inf'))

        print(f"\nğŸ’¡ æ€§èƒ½å»ºè­°:")
        if simple_time < fast_time:
            speedup = fast_time / simple_time if simple_time > 0 else 1
            print(f"  - Simple æ¨¡å¼æ¯” Fast æ¨¡å¼å¿« {speedup:.1f}x")
            print(f"  - å»ºè­°ä½¿ç”¨ Simple æ¨¡å¼ï¼ˆé»˜èªï¼‰")
        else:
            speedup = simple_time / fast_time if fast_time > 0 else 1
            print(f"  - Fast æ¨¡å¼æ¯” Simple æ¨¡å¼å¿« {speedup:.1f}x")
            print(f"  - åœ¨æ­¤å ´æ™¯ä¸‹ Fast æ¨¡å¼è¡¨ç¾æ›´å¥½")


if __name__ == "__main__":
    main()