#!/usr/bin/env python3
"""
å‚…ç«‹è‘‰ç‰¹å¾µæå¤±è¶…è§£æåº¦å„ªåŒ–å¿«é€Ÿæ¸¬è©¦è…³æœ¬

é€™æ˜¯ä¸€å€‹è¼•é‡ç´šæ¸¬è©¦è…³æœ¬ï¼Œç”¨æ–¼å¿«é€Ÿé©—è­‰å‚…ç«‹è‘‰ç‰¹å¾µæå¤±åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚

ä½¿ç”¨æ–¹æ³•:
    python docs/hina/test_fourier_super_resolution.py
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import sys
import os
import time

# æ·»åŠ åº«è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

def test_imports():
    """æ¸¬è©¦å¿…è¦çš„å°å…¥æ˜¯å¦æ­£å¸¸"""
    print("ğŸ” æ¸¬è©¦å°å…¥...")
    try:
        from library.hina_adaptive import HinaAdaptive
        print("âœ… HinaAdaptive å°å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ å°å…¥å¤±æ•—: {e}")
        return False

def test_fourier_optimizer_creation():
    """æ¸¬è©¦å‚…ç«‹è‘‰å„ªåŒ–å™¨å‰µå»º"""
    print("\nğŸ” æ¸¬è©¦å„ªåŒ–å™¨å‰µå»º...")
    try:
        from library.hina_adaptive import HinaAdaptive

        # å‰µå»ºç°¡å–®æ¨¡å‹
        model = nn.Conv2d(3, 64, 3, padding=1)

        # å‰µå»ºå¸¶å‚…ç«‹è‘‰ç‰¹å¾µçš„å„ªåŒ–å™¨
        optimizer = HinaAdaptive(
            model.parameters(),
            lr=1e-4,
            fourier_feature_loss=True,
            super_resolution_mode=True,
            super_resolution_scale=4,
            fourier_high_freq_preservation=0.3,
            fourier_detail_enhancement=0.25,
            fourier_blur_suppression=0.2,
            memory_efficient=True
        )

        print("âœ… å‚…ç«‹è‘‰å„ªåŒ–å™¨å‰µå»ºæˆåŠŸ")

        # æª¢æŸ¥é…ç½®
        info = optimizer.get_optimization_info()
        fourier_config = info.get('fourier_super_resolution_config', {})

        print(f"   è¶…è§£æåº¦æ¨¡å¼: {optimizer.super_resolution_mode}")
        print(f"   æ”¾å¤§å€æ•¸: {optimizer.super_resolution_scale}")
        print(f"   é«˜é »ä¿æŒ: {fourier_config.get('fourier_high_freq_preservation', 'N/A')}")

        return True, optimizer, model
    except Exception as e:
        print(f"âŒ å„ªåŒ–å™¨å‰µå»ºå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False, None, None

def test_fourier_forward_backward():
    """æ¸¬è©¦å‰å‘å’Œåå‘å‚³æ’­"""
    print("\nğŸ” æ¸¬è©¦å‰å‘åå‘å‚³æ’­...")
    try:
        from library.hina_adaptive import HinaAdaptive

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"   ä½¿ç”¨è¨­å‚™: {device}")

        # å‰µå»ºæ¸¬è©¦æ¨¡å‹
        model = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 3, 3, padding=1)
        ).to(device)

        # å‰µå»ºå„ªåŒ–å™¨
        optimizer = HinaAdaptive(
            model.parameters(),
            lr=1e-4,
            fourier_feature_loss=True,
            super_resolution_mode=True,
            super_resolution_scale=4,
            memory_efficient=True,
            vram_budget_gb=4.0
        )

        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        batch_size = 2
        input_tensor = torch.randn(batch_size, 3, 32, 32, device=device)
        target_tensor = torch.randn(batch_size, 3, 32, 32, device=device)

        # å‰å‘å‚³æ’­
        output = model(input_tensor)
        loss = F.mse_loss(output, target_tensor)

        print(f"   è¼¸å…¥å½¢ç‹€: {input_tensor.shape}")
        print(f"   è¼¸å‡ºå½¢ç‹€: {output.shape}")
        print(f"   åˆå§‹æå¤±: {loss.item():.6f}")

        # åå‘å‚³æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # å†æ¬¡å‰å‘å‚³æ’­æª¢æŸ¥
        output2 = model(input_tensor)
        loss2 = F.mse_loss(output2, target_tensor)

        print(f"   æ›´æ–°å¾Œæå¤±: {loss2.item():.6f}")
        print(f"   æå¤±è®ŠåŒ–: {loss2.item() - loss.item():+.6f}")

        print("âœ… å‰å‘åå‘å‚³æ’­æ¸¬è©¦æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âŒ å‰å‘åå‘å‚³æ’­æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_fourier_frequency_analysis():
    """æ¸¬è©¦å‚…ç«‹è‘‰é »ç‡åˆ†æåŠŸèƒ½"""
    print("\nğŸ” æ¸¬è©¦å‚…ç«‹è‘‰é »ç‡åˆ†æ...")
    try:
        from library.hina_adaptive import HinaAdaptive

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # å‰µå»ºæ¸¬è©¦æ¨¡å‹
        model = nn.Conv2d(3, 16, 3, padding=1).to(device)

        # å‰µå»ºå„ªåŒ–å™¨
        optimizer = HinaAdaptive(
            model.parameters(),
            fourier_feature_loss=True,
            super_resolution_mode=True,
            super_resolution_scale=4
        )

        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        input_tensor = torch.randn(1, 3, 16, 16, device=device)
        target_tensor = torch.randn(1, 16, 16, 16, device=device)

        # å‰å‘åå‘å‚³æ’­
        output = model(input_tensor)
        loss = F.mse_loss(output, target_tensor)

        optimizer.zero_grad()
        loss.backward()

        # æª¢æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å«å‚…ç«‹è‘‰åˆ†æçš„å½±éŸ¿
        if model.weight.grad is not None:
            grad_norm = torch.norm(model.weight.grad).item()
            print(f"   æ¢¯åº¦ç¯„æ•¸: {grad_norm:.6f}")

            # æª¢æŸ¥æ˜¯å¦æœ‰å‚…ç«‹è‘‰ç·©å­˜
            if hasattr(optimizer, 'fourier_cache'):
                print(f"   å‚…ç«‹è‘‰ç·©å­˜é …æ•¸: {len(optimizer.fourier_cache)}")

            print("âœ… å‚…ç«‹è‘‰é »ç‡åˆ†ææ¸¬è©¦æˆåŠŸ")
            return True
        else:
            print("âš ï¸  ç„¡æ¢¯åº¦ç”¢ç”Ÿï¼Œå¯èƒ½æ¨¡å‹è¨­ç½®æœ‰å•é¡Œ")
            return False

    except Exception as e:
        print(f"âŒ å‚…ç«‹è‘‰é »ç‡åˆ†ææ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_memory_optimization():
    """æ¸¬è©¦è¨˜æ†¶é«”å„ªåŒ–åŠŸèƒ½"""
    print("\nğŸ” æ¸¬è©¦è¨˜æ†¶é«”å„ªåŒ–...")
    try:
        from library.hina_adaptive import HinaAdaptive

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # å‰µå»ºè¼ƒå¤§çš„æ¨¡å‹
        model = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 3, 3, padding=1)
        ).to(device)

        # æ¸¬è©¦ä¸åŒçš„è¨˜æ†¶é«”è¨­ç½®
        for memory_efficient in [False, True]:
            print(f"\n   è¨˜æ†¶é«”å„ªåŒ–: {memory_efficient}")

            optimizer = HinaAdaptive(
                model.parameters(),
                fourier_feature_loss=True,
                super_resolution_mode=True,
                memory_efficient=memory_efficient,
                reduce_precision=memory_efficient,
                vram_budget_gb=4.0
            )

            # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”
            if torch.cuda.is_available():
                initial_memory = torch.cuda.memory_allocated()

            # é€²è¡Œå¹¾æ­¥è¨“ç·´
            for step in range(3):
                input_tensor = torch.randn(2, 3, 32, 32, device=device)
                target_tensor = torch.randn(2, 3, 32, 32, device=device)

                output = model(input_tensor)
                loss = F.mse_loss(output, target_tensor)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

            # æª¢æŸ¥è¨˜æ†¶é«”ç‹€æ…‹
            if torch.cuda.is_available():
                current_memory = torch.cuda.memory_allocated()
                memory_stats = optimizer.get_memory_stats()
                print(f"     è¨˜æ†¶é«”ä½¿ç”¨: {(current_memory - initial_memory) / 1024**2:.1f}MB")
                print(f"     è¨˜æ†¶é«”å£“åŠ›: {memory_stats['memory_pressure']:.1%}")

            # æ¸…ç†
            optimizer.cleanup_resources()

        print("âœ… è¨˜æ†¶é«”å„ªåŒ–æ¸¬è©¦æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âŒ è¨˜æ†¶é«”å„ªåŒ–æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_different_scales():
    """æ¸¬è©¦ä¸åŒçš„è¶…è§£æåº¦å€æ•¸"""
    print("\nğŸ” æ¸¬è©¦ä¸åŒè¶…è§£æåº¦å€æ•¸...")
    try:
        from library.hina_adaptive import HinaAdaptive

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        model = nn.Conv2d(3, 16, 3, padding=1).to(device)

        for scale in [2, 4, 8]:
            print(f"\n   æ¸¬è©¦ {scale}x è¶…è§£æåº¦...")

            optimizer = HinaAdaptive(
                model.parameters(),
                fourier_feature_loss=True,
                super_resolution_mode=True,
                super_resolution_scale=scale,
                memory_efficient=True
            )

            # æ¸¬è©¦è¨“ç·´æ­¥é©Ÿ
            input_tensor = torch.randn(1, 3, 16, 16, device=device)
            target_tensor = torch.randn(1, 16, 16, 16, device=device)

            output = model(input_tensor)
            loss = F.mse_loss(output, target_tensor)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"     âœ… {scale}x é…ç½®å·¥ä½œæ­£å¸¸")

            # æ¸…ç†
            optimizer.cleanup_resources()

        print("âœ… ä¸åŒå€æ•¸æ¸¬è©¦æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âŒ ä¸åŒå€æ•¸æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance_benchmark():
    """ç°¡å–®çš„æ€§èƒ½åŸºæº–æ¸¬è©¦"""
    print("\nğŸ” æ€§èƒ½åŸºæº–æ¸¬è©¦...")
    try:
        from library.hina_adaptive import HinaAdaptive

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # å‰µå»ºæ¸¬è©¦æ¨¡å‹
        model = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 3, 3, padding=1)
        ).to(device)

        # æ¸¬è©¦æ¨™æº– Adam å„ªåŒ–å™¨
        print("   æ¸¬è©¦æ¨™æº– Adam...")
        adam_optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

        start_time = time.time()
        for step in range(10):
            input_tensor = torch.randn(2, 3, 32, 32, device=device)
            target_tensor = torch.randn(2, 3, 32, 32, device=device)

            output = model(input_tensor)
            loss = F.mse_loss(output, target_tensor)

            adam_optimizer.zero_grad()
            loss.backward()
            adam_optimizer.step()

        adam_time = time.time() - start_time
        print(f"     Adam æ™‚é–“: {adam_time:.3f}s")

        # æ¸¬è©¦å‚…ç«‹è‘‰ HinaAdaptive å„ªåŒ–å™¨
        print("   æ¸¬è©¦å‚…ç«‹è‘‰ HinaAdaptive...")
        fourier_optimizer = HinaAdaptive(
            model.parameters(),
            lr=1e-4,
            fourier_feature_loss=True,
            super_resolution_mode=True,
            memory_efficient=True
        )

        start_time = time.time()
        for step in range(10):
            input_tensor = torch.randn(2, 3, 32, 32, device=device)
            target_tensor = torch.randn(2, 3, 32, 32, device=device)

            output = model(input_tensor)
            loss = F.mse_loss(output, target_tensor)

            fourier_optimizer.zero_grad()
            loss.backward()
            fourier_optimizer.step()

        fourier_time = time.time() - start_time
        print(f"     Fourier HinaAdaptive æ™‚é–“: {fourier_time:.3f}s")

        # è¨ˆç®—æ€§èƒ½é–‹éŠ·
        overhead = (fourier_time - adam_time) / adam_time * 100
        print(f"     æ€§èƒ½é–‹éŠ·: {overhead:+.1f}%")

        if overhead < 50:
            print("âœ… æ€§èƒ½é–‹éŠ·åœ¨å¯æ¥å—ç¯„åœå…§")
        else:
            print("âš ï¸  æ€§èƒ½é–‹éŠ·è¼ƒé«˜ï¼Œè€ƒæ…®å•Ÿç”¨æ›´å¤šè¨˜æ†¶é«”å„ªåŒ–")

        return True

    except Exception as e:
        print(f"âŒ æ€§èƒ½åŸºæº–æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ¨ å‚…ç«‹è‘‰ç‰¹å¾µæå¤±è¶…è§£æåº¦å„ªåŒ–æ¸¬è©¦")
    print("=" * 50)

    test_results = {}

    # é‹è¡Œæ‰€æœ‰æ¸¬è©¦
    tests = [
        ("å°å…¥æ¸¬è©¦", test_imports),
        ("å„ªåŒ–å™¨å‰µå»º", test_fourier_optimizer_creation),
        ("å‰å‘åå‘å‚³æ’­", test_fourier_forward_backward),
        ("å‚…ç«‹è‘‰é »ç‡åˆ†æ", test_fourier_frequency_analysis),
        ("è¨˜æ†¶é«”å„ªåŒ–", test_memory_optimization),
        ("ä¸åŒå€æ•¸", test_different_scales),
        ("æ€§èƒ½åŸºæº–", test_performance_benchmark)
    ]

    passed_tests = 0
    total_tests = len(tests)

    for test_name, test_func in tests:
        try:
            if test_name == "å„ªåŒ–å™¨å‰µå»º":
                result = test_func()
                if isinstance(result, tuple):
                    test_results[test_name] = result[0]
                else:
                    test_results[test_name] = result
            else:
                test_results[test_name] = test_func()

            if test_results[test_name]:
                passed_tests += 1
        except Exception as e:
            print(f"âŒ {test_name} æ¸¬è©¦ç•°å¸¸: {e}")
            test_results[test_name] = False

    # ç¸½çµçµæœ
    print("\n" + "=" * 50)
    print("ğŸ æ¸¬è©¦ç¸½çµ")
    print("=" * 50)

    for test_name, result in test_results.items():
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        print(f"   {test_name}: {status}")

    print(f"\nğŸ“Š ç¸½é«”çµæœ: {passed_tests}/{total_tests} æ¸¬è©¦é€šé")

    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼å‚…ç«‹è‘‰ç‰¹å¾µæå¤±åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        print("\nğŸ’¡ æ¥ä¸‹ä¾†å¯ä»¥:")
        print("   1. é‹è¡Œå®Œæ•´ç¤ºä¾‹: python docs/hina/fourier_super_resolution_example.py")
        print("   2. é–±è®€ä½¿ç”¨æŒ‡å—: docs/hina/FOURIER_SUPER_RESOLUTION_GUIDE.md")
        print("   3. åœ¨å¯¦éš›é …ç›®ä¸­ä½¿ç”¨å‚…ç«‹è‘‰ç‰¹å¾µæå¤±å„ªåŒ–")

        return True
    elif passed_tests >= total_tests * 0.7:
        print("âš ï¸  å¤§éƒ¨åˆ†æ¸¬è©¦é€šéï¼ŒåŠŸèƒ½åŸºæœ¬å¯ç”¨ã€‚")
        print("   å»ºè­°æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦é …ç›®ã€‚")
        return True
    else:
        print("âŒ å¤šé …æ¸¬è©¦å¤±æ•—ï¼Œå¯èƒ½å­˜åœ¨åš´é‡å•é¡Œã€‚")
        print("   è«‹æª¢æŸ¥ä»£ç¢¼æˆ–ç’°å¢ƒé…ç½®ã€‚")
        return False

if __name__ == "__main__":
    try:
        success = main()
        exit_code = 0 if success else 1
    except KeyboardInterrupt:
        print("\nâš ï¸  æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        exit_code = 1
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”Ÿæœªè™•ç†çš„éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        exit_code = 1
    finally:
        # æ¸…ç†è³‡æº
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        print("\nğŸ§¹ è³‡æºæ¸…ç†å®Œæˆ")

    exit(exit_code)