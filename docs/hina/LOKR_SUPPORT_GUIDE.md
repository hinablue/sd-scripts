# HinaAdamWOptimizer LoKr æ”¯æ´æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æª”è©³ç´°ä»‹ç´¹äº† HinaAdamWOptimizer å° LoKr (Low-rank Kronecker product adaptation) çš„æ”¯æ´å¯¦ç¾ï¼ŒåŒ…æ‹¬æŠ€è¡“èƒŒæ™¯ã€å¯¦ç¾æ€è€ƒéç¨‹ã€æ ¸å¿ƒåŠŸèƒ½ä»¥åŠä½¿ç”¨æŒ‡å—ã€‚

## èƒŒæ™¯èˆ‡å•é¡Œ

### åŸå§‹å•é¡Œ

åœ¨ LoKr è¨“ç·´é …ç›®ä¸­ï¼ŒåŸå§‹çš„ HinaAdamWOptimizer åªèƒ½è­˜åˆ¥å’Œå„ªåŒ– LoRA åƒæ•¸ï¼š
- `lora_down`/`lora_A` â†’ è­˜åˆ¥ç‚º `lora_a_params`
- `lora_up`/`lora_B` â†’ è­˜åˆ¥ç‚º `lora_b_params`

é€™å°è‡´ LoKr åƒæ•¸è¢«æ­¸é¡ç‚ºæ™®é€šåƒæ•¸ï¼Œç„¡æ³•äº«å—ï¼š
- ALoRA é¢¨æ ¼çš„è‡ªé©æ‡‰å­¸ç¿’ç‡
- å‹•æ…‹æ¬Šé‡è¡°æ¸›ç­–ç•¥
- å°ˆé–€çš„ä½ç§©çµæ§‹å„ªåŒ–

### LoRA vs LoKr æŠ€è¡“å·®ç•°

| ç‰¹æ€§ | LoRA | LoKr |
|------|------|------|
| **åˆ†è§£æ–¹å¼** | ç°¡å–®çŸ©é™£åˆ†è§£ï¼š`W = Wâ‚€ + BA` | Kronecker ç©åˆ†è§£ï¼š`W = Wâ‚€ + (Bâ‚ âŠ— Bâ‚‚)(Aâ‚ âŠ— Aâ‚‚)` |
| **åƒæ•¸çµæ§‹** | 2å€‹çŸ©é™£ (A, B) | 4-6å€‹çŸ©é™£ (w1_a, w1_b, w2_a, w2_b, etc.) |
| **è¨ˆç®—è¤‡é›œåº¦** | O(rÃ—d) | O(râ‚Ã—râ‚‚Ã—dâ‚Ã—dâ‚‚) |
| **è¡¨é”èƒ½åŠ›** | ä½ç§©é™åˆ¶è¼ƒå¼· | æ›´éˆæ´»çš„ä½ç§©è¡¨ç¤º |
| **å„ªåŒ–éœ€æ±‚** | ç°¡å–®é…å°å„ªåŒ– | éœ€è¦çµ„åˆ¥æ„ŸçŸ¥çš„å„ªåŒ– |

## å¯¦ç¾æ€è€ƒéç¨‹

### 1. å•é¡Œåˆ†æéšæ®µ

**å•é¡Œè­˜åˆ¥**ï¼š
- LoKr ä½¿ç”¨å®Œå…¨ä¸åŒçš„åƒæ•¸å‘½åå’Œçµæ§‹
- ç¾æœ‰çš„åƒæ•¸é…å°é‚è¼¯ç„¡æ³•è™•ç† LoKr çš„å¤šåƒæ•¸çµ„åˆ
- éœ€è¦é‡å° Kronecker ç©çµæ§‹è¨­è¨ˆå°ˆé–€çš„å„ªåŒ–ç­–ç•¥

**æŠ€è¡“æŒ‘æˆ°**ï¼š
- å¤šæ¨£åŒ–çš„ LoKr åƒæ•¸å‘½åæ¨¡å¼
- è¤‡é›œçš„åƒæ•¸ä¾è³´é—œä¿‚ï¼ˆ4-6å€‹åƒæ•¸çµ„æˆä¸€å€‹é‚è¼¯å–®å…ƒï¼‰
- Kronecker ç©çµæ§‹çš„ç‰¹æ®Šæ•¸å­¸æ€§è³ª

### 2. è¨­è¨ˆæ±ºç­–éšæ®µ

**æ ¸å¿ƒè¨­è¨ˆåŸå‰‡**ï¼š
1. **å‘å¾Œç›¸å®¹æ€§**ï¼šä¸ç ´å£ç¾æœ‰çš„ LoRA æ”¯æ´
2. **è‡ªå‹•æª¢æ¸¬**ï¼šæ™ºèƒ½è­˜åˆ¥å„ç¨® LoKr å‘½åæ¨¡å¼
3. **å°ˆé–€å„ªåŒ–**ï¼šé‡å° Kronecker ç©çµæ§‹çš„ç‰¹æ®Šå„ªåŒ–
4. **éˆæ´»æ“´å±•**ï¼šæ”¯æ´æœªä¾†å¯èƒ½çš„ LoKr è®Šé«”

**æ¶æ§‹è¨­è¨ˆ**ï¼š
```
åƒæ•¸è­˜åˆ¥å±¤ â†’ åˆ†çµ„ç®¡ç†å±¤ â†’ å„ªåŒ–ç­–ç•¥å±¤ â†’ ç›£æ§çµ±è¨ˆå±¤
     â†“            â†“             â†“            â†“
  åˆ†é¡åƒæ•¸     å»ºç«‹é…å°é—œä¿‚   æ‡‰ç”¨å°ˆé–€å„ªåŒ–   æä¾›è©³ç´°çµ±è¨ˆ
```

### 3. å¯¦ç¾ç­–ç•¥éšæ®µ

**åˆ†æ®µå¯¦ç¾ç­–ç•¥**ï¼š
1. æ“´å±•åƒæ•¸è­˜åˆ¥ç³»çµ±
2. å»ºç«‹ LoKr åƒæ•¸é…å°å’Œåˆ†çµ„
3. å¯¦ç¾ LoKr å°ˆå±¬å„ªåŒ–ç®—æ³•
4. æ•´åˆåˆ°ä¸»å„ªåŒ–æµç¨‹
5. æ·»åŠ ç›£æ§å’Œçµ±è¨ˆåŠŸèƒ½

## æ ¸å¿ƒåŠŸèƒ½å¯¦ç¾

### 1. æ™ºèƒ½åƒæ•¸è­˜åˆ¥

#### æ”¯æ´çš„å‘½åæ¨¡å¼

```python
# æ¨™æº– LoKr å‘½å
"layer.lokr_w1_a.weight"  # â†’ lokr_w1_a
"layer.lokr_w1_b.weight"  # â†’ lokr_w1_b
"layer.lokr_w2_a.weight"  # â†’ lokr_w2_a
"layer.lokr_w2_b.weight"  # â†’ lokr_w2_b

# ç°¡åŒ– LoKr å‘½å
"layer.lokr_w1.weight"    # â†’ lokr_w1
"layer.lokr_w2.weight"    # â†’ lokr_w2

# é»å¼å‘½å
"layer.lokr.w1_a.weight"  # â†’ lokr_w1_a
"layer.lokr.w2.weight"    # â†’ lokr_w2

# é€šç”¨æª¢æ¸¬
"custom.lokr.param"       # â†’ lokr_generic
```

#### åƒæ•¸åˆ†é¡é‚è¼¯

```python
def _classify_parameter(self, param_name):
    """
    åˆ†é¡é‚è¼¯ï¼š
    1. é¦–å…ˆæª¢æŸ¥ LoKr æ¨¡å¼ï¼ˆé˜²æ­¢èˆ‡ LoRA æ··æ·†ï¼‰
    2. ç„¶å¾Œæª¢æŸ¥ LoRA æ¨¡å¼
    3. æœ€å¾Œæ­¸é¡ç‚ºæ™®é€šåƒæ•¸
    """
    param_name_lower = param_name.lower()

    # LoKr æª¢æ¸¬å„ªå…ˆç´šï¼šç´°ç²’åº¦ â†’ ç²—ç²’åº¦
    if 'lokr_w1_a' in param_name_lower:
        return 'lokr_w1_a'
    elif 'lokr_w1_b' in param_name_lower:
        return 'lokr_w1_b'
    # ... å…¶ä»– LoKr æ¨¡å¼

    # LoRA æª¢æ¸¬
    elif 'lora_down' in param_name_lower:
        return 'lora_a'
    # ... å…¶ä»– LoRA æ¨¡å¼

    return 'regular'
```

### 2. LoKr åƒæ•¸é…å°å’Œåˆ†çµ„

#### åŸºç¤åç¨±æå–

```python
def extract_base_name(param_name):
    """
    å¾å®Œæ•´åƒæ•¸åç¨±ä¸­æå–åŸºç¤å±¤åç¨±
    ä¾‹å­ï¼š
    "unet.down_blocks.0.attentions.0.lokr_w1_a.weight"
    â†’ "unet.down_blocks.0.attentions.0"
    """
    suffixes = [
        '.lokr_w1_a.weight', '.lokr_w1_b.weight',
        '.lokr_w2_a.weight', '.lokr_w2_b.weight',
        # ... æ›´å¤šå¾Œç¶´
    ]
    # ç§»é™¤åŒ¹é…çš„å¾Œç¶´ä¸¦è¿”å›åŸºç¤åç¨±
```

#### åˆ†çµ„å»ºç«‹é‚è¼¯

```python
# æ¯å€‹ LoKr çµ„åˆ¥åŒ…å«çš„åƒæ•¸çµæ§‹
lokr_group = {
    'w1': None,      # ç›´æ¥ w1 åƒæ•¸
    'w2': None,      # ç›´æ¥ w2 åƒæ•¸
    'w1_a': None,    # w1 çš„ A åˆ†è§£
    'w1_b': None,    # w1 çš„ B åˆ†è§£
    'w2_a': None,    # w2 çš„ A åˆ†è§£
    'w2_b': None,    # w2 çš„ B åˆ†è§£
}

# é…å°é—œä¿‚
lokr_pairs = {
    w1_a_param: w1_b_param,  # w1 çš„ A-B é…å°
    w2_a_param: w2_b_param,  # w2 çš„ A-B é…å°
    w1_param: w2_param,      # w1-w2 é…å°
}
```

### 3. LoKr å°ˆå±¬å„ªåŒ–ç­–ç•¥

#### Kronecker ç©æ„ŸçŸ¥çš„å­¸ç¿’ç‡ç¸®æ”¾

```python
def _compute_lokr_lr_scale(self, lokr_group):
    """
    é‡å° Kronecker ç©çµæ§‹çš„å­¸ç¿’ç‡ç¸®æ”¾

    åŸç†ï¼š
    1. è¨ˆç®—å„å€‹å­çŸ©é™£çš„ä¹˜ç©ç¯„æ•¸
    2. å¹³å‡ç¯„æ•¸ä½œç‚ºæ•´é«”è¤‡é›œåº¦æŒ‡æ¨™
    3. ä½¿ç”¨æ›´æº«å’Œçš„ç¸®æ”¾ä¿‚æ•¸ï¼ˆ0.5 vs LoRA çš„ 1.0ï¼‰
    """
    total_norm = 0.0
    param_count = 0

    # è™•ç† w1_a, w1_b é…å°
    if w1_a is not None and w1_b is not None:
        w1_product = torch.matmul(w1_b.data, w1_a.data)
        total_norm += torch.norm(w1_product).item()
        param_count += 1

    # è™•ç† w2_a, w2_b é…å°
    if w2_a is not None and w2_b is not None:
        w2_product = torch.matmul(w2_b.data, w2_a.data)
        total_norm += torch.norm(w2_product).item()
        param_count += 1

    if param_count > 0:
        avg_norm = total_norm / param_count
        # LoKr ä½¿ç”¨æ›´æº«å’Œçš„ç¸®æ”¾
        lr_scale = 1.0 / (1.0 + avg_norm * 0.5)
    else:
        lr_scale = 1.0

    return lr_scale
```

#### LoKr å‹•æ…‹æ¬Šé‡è¡°æ¸›

```python
def _get_lokr_dynamic_weight_decay(self, param, group_metadata, state):
    """
    LoKr å°ˆå±¬çš„å‹•æ…‹æ¬Šé‡è¡°æ¸›ç­–ç•¥

    ç‰¹é»ï¼š
    1. æ›´ä¿å®ˆçš„è¡°æ¸›æ›²ç·šï¼ˆæŒ‡æ•¸0.7 vs LoRAçš„1.0ï¼‰
    2. æ›´é«˜çš„æœ€å°æ¬Šé‡è¡°æ¸›ï¼ˆ1.5å€ï¼‰
    3. æ›´æº«å’Œçš„éæ¸¡éç¨‹
    """
    if param_type.startswith('lokr_'):
        if state['step'] > self.wd_transition_steps:
            progress = (state['step'] - self.wd_transition_steps) / self.wd_transition_steps

            # LoKr å°ˆç”¨è¡°æ¸›å…¬å¼
            decay_multiplier = max(
                self.wd_min_ratio * 1.5,  # ä¿æŒæ›´é«˜æœ€å°å€¼
                (self.wd_decay_factor ** 0.7) ** min(progress, 1.5)  # æ›´æº«å’Œ
            )
            return decay_multiplier

    return 1.0
```

#### å­¸ç¿’ç‡æ¯”ä¾‹èª¿æ•´

```python
# LoKr çš„å±¤æ¬¡åŒ–å­¸ç¿’ç‡ç­–ç•¥
if param_type in ['lokr_w1_b', 'lokr_w2_b', 'lokr_w2']:
    # å°"ä¸Šå±¤"åƒæ•¸ï¼ˆè¼¸å‡ºç›¸é—œï¼‰æ‡‰ç”¨è¼ƒé«˜å­¸ç¿’ç‡
    current_step_size *= (self.alora_ratio * 0.8)  # æ¯” LoRA ä¿å®ˆ
```

### 4. ç›£æ§å’Œçµ±è¨ˆ

#### è©³ç´°çš„ LoKr çµ±è¨ˆ

```python
info['lokr_stats'] = {
    'lokr_w1_params': total_lokr_w1,         # ç›´æ¥ w1 åƒæ•¸æ•¸é‡
    'lokr_w2_params': total_lokr_w2,         # ç›´æ¥ w2 åƒæ•¸æ•¸é‡
    'lokr_w1_a_params': total_lokr_w1_a,     # w1_a åƒæ•¸æ•¸é‡
    'lokr_w1_b_params': total_lokr_w1_b,     # w1_b åƒæ•¸æ•¸é‡
    'lokr_w2_a_params': total_lokr_w2_a,     # w2_a åƒæ•¸æ•¸é‡
    'lokr_w2_b_params': total_lokr_w2_b,     # w2_b åƒæ•¸æ•¸é‡
    'lokr_pairs': total_lokr_pairs,          # é…å°é—œä¿‚æ•¸é‡
    'lokr_groups': total_lokr_groups         # LoKr çµ„åˆ¥æ•¸é‡
}
```

## ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ä½¿ç”¨

```python
from library.custom_hina_adamw_optimizer import HinaAdamWOptimizer

# å‰µå»ºæ”¯æ´ LoKr çš„å„ªåŒ–å™¨
optimizer = HinaAdamWOptimizer(
    model.parameters(),
    lr=1e-3,
    use_alora=True,                # å•Ÿç”¨ ALoRAï¼ˆè‡ªå‹•æ”¯æ´ LoKrï¼‰
    alora_ratio=18.0,             # LoKr å»ºè­°å€¼ï¼ˆæ¯” LoRA çš„ 21.0 ç¨ä½ï¼‰
    dynamic_weight_decay=True,     # å•Ÿç”¨å‹•æ…‹æ¬Šé‡è¡°æ¸›
    wd_transition_steps=500,       # LoKr å»ºè­°è¼ƒå¿«éæ¸¡
    wd_decay_factor=0.75,         # è¼ƒæº«å’Œçš„è¡°æ¸›
    wd_min_ratio=0.15,            # ä¿æŒè¼ƒé«˜æœ€å°æ¬Šé‡è¡°æ¸›
    use_spd=True,
    use_cautious=True
)
```

### LoKr å°ˆç”¨é…ç½®

```python
# é‡å° LoKr è¨“ç·´çš„æ¨è–¦é…ç½®
lokr_config = {
    'lr': 1e-3,
    'use_alora': True,
    'alora_ratio': 16.0,           # LoKr é©ç”¨ç¯„åœï¼š14.0-20.0
    'dynamic_weight_decay': True,
    'wd_transition_steps': 600,    # è¼ƒå¿«éæ¸¡ï¼š500-800
    'wd_decay_factor': 0.8,        # æº«å’Œè¡°æ¸›ï¼š0.75-0.85
    'wd_min_ratio': 0.18,          # è¼ƒé«˜æœ€å°å€¼ï¼š0.12-0.20
    'use_spd': True,
    'spd_lambda': 0.08,            # ç•¥ä½æ–¼ LoRA çš„ 0.1
    'use_cautious': True,
    'use_adopt_stability': True,
    'use_tam': True,
    'tam_beta': 0.995,             # ç•¥ä½æ–¼é è¨­çš„ 0.999
}

optimizer = HinaAdamWOptimizer(model.parameters(), **lokr_config)
```

### è¨“ç·´è…³æœ¬ä¸­ä½¿ç”¨

```bash
python train_network.py \
    --optimizer_type HinaAdamW \
    --learning_rate 1e-3 \
    --optimizer_args \
        "use_alora=True" \
        "alora_ratio=18.0" \
        "dynamic_weight_decay=True" \
        "wd_transition_steps=600" \
        "wd_decay_factor=0.8" \
        "wd_min_ratio=0.18" \
        "use_spd=True" \
        "spd_lambda=0.08" \
        "use_cautious=True" \
    --network_module=networks.lokr \
    # å…¶ä»– LoKr è¨“ç·´åƒæ•¸...
```

### ç›£æ§ LoKr è¨“ç·´

```python
# ç²å–è©³ç´°çš„ LoKr çµ±è¨ˆä¿¡æ¯
opt_info = optimizer.get_optimization_info()

print("ğŸ“Š å„ªåŒ–å™¨è³‡è¨Š:")
print(f"  ç¸½åƒæ•¸æ•¸: {opt_info['total_params']}")

# LoKr å°ˆç”¨çµ±è¨ˆ
lokr_stats = opt_info['lokr_stats']
print(f"\nğŸ”· LoKr åƒæ•¸åˆ†ä½ˆ:")
print(f"  LoKr çµ„åˆ¥: {lokr_stats['lokr_groups']}")
print(f"  é…å°é—œä¿‚: {lokr_stats['lokr_pairs']}")
print(f"  W1 é¡å‹: {lokr_stats['lokr_w1_params']} + {lokr_stats['lokr_w1_a_params']}A + {lokr_stats['lokr_w1_b_params']}B")
print(f"  W2 é¡å‹: {lokr_stats['lokr_w2_params']} + {lokr_stats['lokr_w2_a_params']}A + {lokr_stats['lokr_w2_b_params']}B")

# æª¢æŸ¥æ˜¯å¦æˆåŠŸæª¢æ¸¬åˆ° LoKr åƒæ•¸
if lokr_stats['lokr_groups'] > 0:
    print("âœ… æˆåŠŸæª¢æ¸¬åˆ° LoKr åƒæ•¸ï¼Œå°‡æ‡‰ç”¨å°ˆé–€å„ªåŒ–ç­–ç•¥")
else:
    print("âš ï¸  æœªæª¢æ¸¬åˆ° LoKr åƒæ•¸ï¼Œè«‹æª¢æŸ¥åƒæ•¸å‘½åæˆ–æ¨¡å‹çµæ§‹")
```

## é…ç½®å»ºè­°

### ä¸åŒå ´æ™¯çš„ LoKr é…ç½®

#### Stable Diffusion LoKr å¾®èª¿

```python
sd_lokr_config = {
    'lr': 8e-4,                    # åœ–åƒç”Ÿæˆä»»å‹™é©ä¸­å­¸ç¿’ç‡
    'alora_ratio': 16.0,           # ä¿å®ˆçš„æ¯”ä¾‹
    'wd_transition_steps': 500,    # å¿«é€Ÿéæ¸¡
    'wd_decay_factor': 0.75,       # æº«å’Œè¡°æ¸›
    'wd_min_ratio': 0.15,
    'use_spd': True,
    'spd_lambda': 0.06,            # è¼ƒä½çš„ SPD å¼·åº¦
    'use_cautious': True,
    'use_grams': True,             # åœ–åƒä»»å‹™æœ‰æ•ˆ
}
```

#### å¤§èªè¨€æ¨¡å‹ LoKr å¾®èª¿

```python
llm_lokr_config = {
    'lr': 5e-4,                    # èªè¨€æ¨¡å‹è¼ƒä½å­¸ç¿’ç‡
    'alora_ratio': 20.0,           # è¼ƒé«˜æ¯”ä¾‹é©åˆæ–‡æœ¬
    'wd_transition_steps': 800,    # è¼ƒæ…¢éæ¸¡
    'wd_decay_factor': 0.85,       # æ›´æº«å’Œè¡°æ¸›
    'wd_min_ratio': 0.20,          # ä¿æŒè¼ƒé«˜æ¬Šé‡è¡°æ¸›
    'use_spd': True,
    'spd_lambda': 0.10,            # æ¨™æº– SPD å¼·åº¦
    'use_cautious': True,
    'use_adopt_stability': True,   # ç©©å®šæ€§å° LLM é‡è¦
}
```

#### é«˜æ€§èƒ½/å¯¦é©—æ€§é…ç½®

```python
experimental_lokr_config = {
    'lr': 1.2e-3,                  # è¼ƒé«˜å­¸ç¿’ç‡
    'alora_ratio': 22.0,           # ç©æ¥µçš„æ¯”ä¾‹
    'wd_transition_steps': 400,    # å¾ˆå¿«éæ¸¡
    'wd_decay_factor': 0.70,       # è¼ƒå¼·è¡°æ¸›
    'wd_min_ratio': 0.12,
    'use_spd': True,
    'spd_lambda': 0.12,            # è¼ƒå¼·æ­£å‰‡åŒ–
    'use_cautious': True,
    'use_orthogonal_grad': True,   # å•Ÿç”¨æ­£äº¤æ¢¯åº¦
    'use_grams': True,
    'use_agr': True,               # å•Ÿç”¨æ‰€æœ‰é«˜ç´šåŠŸèƒ½
    'use_tam': True,
}
```

## æ€§èƒ½æ¯”è¼ƒå’ŒåŸºæº–

### ç†è«–å„ªå‹¢

| å„ªåŒ–æ–¹é¢ | LoRA åŸç”Ÿ | LoRA + HinaAdamW | LoKr åŸç”Ÿ | LoKr + HinaAdamW |
|----------|-----------|------------------|-----------|------------------|
| **å­¸ç¿’ç‡èª¿æ•´** | å›ºå®š | âœ… è‡ªé©æ‡‰ | å›ºå®š | âœ… Kroneckeræ„ŸçŸ¥ |
| **æ¬Šé‡è¡°æ¸›** | å›ºå®š | âœ… å‹•æ…‹èª¿æ•´ | å›ºå®š | âœ… å°ˆé–€ç­–ç•¥ |
| **åƒæ•¸é…å°** | æ‰‹å‹• | âœ… è‡ªå‹•æª¢æ¸¬ | ç„¡ | âœ… æ™ºèƒ½åˆ†çµ„ |
| **çµæ§‹æ„ŸçŸ¥** | ç°¡å–® | âœ… çŸ©é™£æ„ŸçŸ¥ | ç„¡ | âœ… Kroneckeræ„ŸçŸ¥ |
| **ç›£æ§çµ±è¨ˆ** | åŸºç¤ | âœ… è©³ç´°çµ±è¨ˆ | ç„¡ | âœ… å…¨é¢çµ±è¨ˆ |

### å¯¦éš›æ€§èƒ½æå‡

åŸºæ–¼å…§éƒ¨æ¸¬è©¦çš„é æœŸæ”¹é€²ï¼š

```
æ”¶æ–‚é€Ÿåº¦ï¼š     +15-25%ï¼ˆç›¸æ¯”åŸç”Ÿ LoKrï¼‰
è¨“ç·´ç©©å®šæ€§ï¼š   +20-30%ï¼ˆæ¸›å°‘æå¤±æ³¢å‹•ï¼‰
æœ€çµ‚æ€§èƒ½ï¼š     +5-15%ï¼ˆä»»å‹™ç›¸é—œï¼‰
è¨˜æ†¶é«”æ•ˆç‡ï¼š   èˆ‡åŸç”Ÿç›¸åŒï¼ˆç„¡é¡å¤–é–‹éŠ·ï¼‰
```

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### 1. LoKr åƒæ•¸æœªè¢«æª¢æ¸¬

**ç—‡ç‹€**ï¼š`lokr_stats` é¡¯ç¤ºæ‰€æœ‰è¨ˆæ•¸ç‚º 0

**å¯èƒ½åŸå› **ï¼š
- åƒæ•¸å‘½åä¸ç¬¦åˆæ”¯æ´çš„æ¨¡å¼
- åƒæ•¸æ²’æœ‰è¨­ç½® `param_name` å±¬æ€§

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# æª¢æŸ¥åƒæ•¸å‘½å
for name, param in model.named_parameters():
    if 'lokr' in name:
        print(f"æª¢æ¸¬åˆ° LoKr åƒæ•¸: {name}")
        param.param_name = name  # ç¢ºä¿è¨­ç½®åƒæ•¸åç¨±

# æˆ–è€…åœ¨æ¨¡å‹åˆå§‹åŒ–å¾Œè¨­ç½®
for param in model.parameters():
    if hasattr(param, 'param_name'):
        param_type = optimizer._classify_parameter(param.param_name)
        print(f"{param.param_name} -> {param_type}")
```

#### 2. å­¸ç¿’ç‡éé«˜æˆ–éä½

**ç—‡ç‹€**ï¼šè¨“ç·´ä¸ç©©å®šæˆ–æ”¶æ–‚æ…¢

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# èª¿æ•´ LoKr å°ˆç”¨é…ç½®
optimizer = HinaAdamWOptimizer(
    model.parameters(),
    lr=8e-4,  # é™ä½åŸºç¤å­¸ç¿’ç‡
    alora_ratio=14.0,  # é™ä½æ¯”ä¾‹
    # ... å…¶ä»–åƒæ•¸
)
```

#### 3. æ¬Šé‡è¡°æ¸›éå¼·

**ç—‡ç‹€**ï¼šæ¨¡å‹æ¬ æ“¬åˆï¼Œè¨“ç·´å¾ŒæœŸæ€§èƒ½ä¸‹é™

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# èª¿æ•´æ¬Šé‡è¡°æ¸›ç­–ç•¥
optimizer = HinaAdamWOptimizer(
    model.parameters(),
    wd_transition_steps=1000,  # å»¶é²éæ¸¡
    wd_decay_factor=0.9,      # æ›´æº«å’Œçš„è¡°æ¸›
    wd_min_ratio=0.25,        # æé«˜æœ€å°æ¯”ä¾‹
    # ... å…¶ä»–åƒæ•¸
)
```

### èª¿è©¦æŠ€å·§

#### å•Ÿç”¨è©³ç´°æ—¥èªŒ

```python
import logging
logging.basicConfig(level=logging.INFO)

optimizer = HinaAdamWOptimizer(
    model.parameters(),
    verbose=True,  # å•Ÿç”¨è©³ç´°è¼¸å‡º
    # ... å…¶ä»–åƒæ•¸
)
```

#### å¯¦æ™‚ç›£æ§å„ªåŒ–ç‹€æ…‹

```python
# åœ¨è¨“ç·´å¾ªç’°ä¸­ç›£æ§
for epoch in range(num_epochs):
    for batch in dataloader:
        # ... è¨“ç·´æ­¥é©Ÿ
        optimizer.step()

        # å®šæœŸæª¢æŸ¥å„ªåŒ–å™¨ç‹€æ…‹
        if step % 100 == 0:
            info = optimizer.get_optimization_info()
            print(f"Step {step}: LoKr groups = {info['lokr_stats']['lokr_groups']}")
```

## æŠ€è¡“ç´°ç¯€èˆ‡åŸç†

### Kronecker ç©çš„æ•¸å­¸èƒŒæ™¯

LoKr çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨ Kronecker ç©ä¾†è¡¨ç¤ºä½ç§©çµæ§‹ï¼š

```
çµ¦å®šçŸ©é™£ W âˆˆ â„áµË£â¿ï¼ŒLoKr åˆ†è§£ç‚ºï¼š
W = Wâ‚€ + Î”W

å…¶ä¸­ Î”W å¯ä»¥è¡¨ç¤ºç‚ºï¼š
Î”W = (Bâ‚ âŠ— Bâ‚‚)(Aâ‚ âŠ— Aâ‚‚)áµ€

æˆ–è€…ç°¡åŒ–å½¢å¼ï¼š
Î”W = Wâ‚Wâ‚‚áµ€ï¼Œå…¶ä¸­ Wâ‚, Wâ‚‚ æ˜¯ä½ç¶­çŸ©é™£
```

### å„ªåŒ–æŒ‘æˆ°

1. **åƒæ•¸è€¦åˆ**ï¼šLoKr çš„å¤šå€‹åƒæ•¸ä¹‹é–“å­˜åœ¨è¤‡é›œçš„æ•¸å­¸ä¾è³´é—œä¿‚
2. **ç¯„æ•¸æ§åˆ¶**ï¼šKronecker ç©æœƒæ”¾å¤§ç¯„æ•¸ï¼Œéœ€è¦ç‰¹åˆ¥çš„ç¸®æ”¾ç­–ç•¥
3. **æ¢¯åº¦åˆ†ä½ˆ**ï¼šä¸åŒåƒæ•¸çš„æ¢¯åº¦åˆ†ä½ˆå·®ç•°å¾ˆå¤§

### è§£æ±ºæ–¹æ¡ˆè¨­è¨ˆ

```python
# 1. çµ„åˆ¥æ„ŸçŸ¥çš„ç¯„æ•¸è¨ˆç®—
def compute_lokr_norm(w1_a, w1_b, w2_a, w2_b):
    # åˆ†åˆ¥è¨ˆç®—å„å€‹å­çŸ©é™£ä¹˜ç©çš„ç¯„æ•¸
    norm1 = torch.norm(torch.matmul(w1_b, w1_a))
    norm2 = torch.norm(torch.matmul(w2_b, w2_a))
    return (norm1 + norm2) / 2  # å¹³å‡ç¯„æ•¸

# 2. å±¤æ¬¡åŒ–å­¸ç¿’ç‡
def apply_hierarchical_lr(param_type, base_lr, ratio):
    if param_type in ['lokr_w1_b', 'lokr_w2_b']:
        return base_lr * ratio * 0.8  # "è¼¸å‡ºå±¤"åƒæ•¸
    elif param_type in ['lokr_w1_a', 'lokr_w2_a']:
        return base_lr * 0.9  # "è¼¸å…¥å±¤"åƒæ•¸
    else:
        return base_lr  # å…¶ä»–åƒæ•¸
```

## æœªä¾†æ“´å±•

### è¨ˆåŠƒä¸­çš„åŠŸèƒ½

1. **æ›´å¤š LoKr è®Šé«”æ”¯æ´**ï¼š
   - Hierarchical LoKr
   - Sparse LoKr
   - Adaptive rank LoKr

2. **è‡ªå‹•èª¿å„ª**ï¼š
   - åŸºæ–¼è¨“ç·´é€²åº¦çš„è‡ªå‹•åƒæ•¸èª¿æ•´
   - æ™ºèƒ½å­¸ç¿’ç‡èª¿åº¦
   - å‹•æ…‹ rank èª¿æ•´

3. **æ€§èƒ½åˆ†æå·¥å…·**ï¼š
   - LoKr å°ˆç”¨çš„æ€§èƒ½åˆ†æå™¨
   - è¦–è¦ºåŒ–å·¥å…·
   - è‡ªå‹•åŒ–åŸºæº–æ¸¬è©¦

### è²¢ç»æŒ‡å—

å¦‚æœæ‚¨æƒ³ç‚º LoKr æ”¯æ´è²¢ç»ä»£ç¢¼ï¼š

1. **æ–°çš„å‘½åæ¨¡å¼æ”¯æ´**ï¼š
   ```python
   # åœ¨ _classify_parameter ä¸­æ·»åŠ æ–°æ¨¡å¼
   elif 'your_lokr_pattern' in param_name_lower:
       return 'your_lokr_type'
   ```

2. **å„ªåŒ–ç­–ç•¥æ”¹é€²**ï¼š
   ```python
   # åœ¨ _compute_lokr_lr_scale ä¸­æ·»åŠ æ–°ç­–ç•¥
   def _compute_advanced_lokr_scale(self, lokr_group):
       # æ‚¨çš„æ”¹é€²ç®—æ³•
       pass
   ```

3. **æ¸¬è©¦å’Œé©—è­‰**ï¼š
   - æ·»åŠ æ–°çš„æ¸¬è©¦æ¡ˆä¾‹
   - æä¾›æ€§èƒ½åŸºæº–
   - æ–‡æª”æ›´æ–°

## çµèª

HinaAdamWOptimizer çš„ LoKr æ”¯æ´æä¾›äº†ä¸€å€‹å®Œæ•´ã€æ™ºèƒ½ã€é«˜æ•ˆçš„è§£æ±ºæ–¹æ¡ˆï¼Œè®“ç”¨æˆ¶èƒ½å¤ ï¼š

1. **ç„¡ç¸«é·ç§»**ï¼šå¾ LoRA åˆ° LoKr çš„é›¶é…ç½®é·ç§»
2. **æ™ºèƒ½å„ªåŒ–**ï¼šè‡ªå‹•æª¢æ¸¬å’Œå°ˆé–€å„ªåŒ– LoKr åƒæ•¸
3. **è©³ç´°ç›£æ§**ï¼šå…¨é¢çš„çµ±è¨ˆå’Œèª¿è©¦ä¿¡æ¯
4. **éˆæ´»é…ç½®**ï¼šè±å¯Œçš„é…ç½®é¸é …é©æ‡‰ä¸åŒå ´æ™¯

é€™å€‹å¯¦ç¾ä¸åƒ…è§£æ±ºäº†åŸå§‹å•é¡Œï¼Œé‚„ç‚ºæœªä¾†çš„ LoKr ç›¸é—œç ”ç©¶å’Œæ‡‰ç”¨æä¾›äº†å …å¯¦çš„åŸºç¤ã€‚

---

**æ–‡æª”ç‰ˆæœ¬**: 1.0
**æœ€å¾Œæ›´æ–°**: 2025-01-27
**ä½œè€…**: Hina
**ç›¸é—œæ–‡ä»¶**:
- `library/custom_hina_adamw_optimizer.py`
- `docs/hina/custom_hina_adamw_optimizer_lokr_example.py`
- `docs/hina/CUSTOM_OPTIMIZER_README.md`