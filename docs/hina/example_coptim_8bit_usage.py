#!/usr/bin/env python3
"""
Automagic_CameAMP_COptim8bit å„ªåŒ–å™¨ä½¿ç”¨ç¯„ä¾‹

é€™å€‹ç¯„ä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨çµåˆ C-Optim ä¸Šä¸‹æ–‡å„ªåŒ–å’Œ 8-bit é‡åŒ–çš„å„ªåŒ–å™¨ã€‚
åŒ…å«ï¼š
1. åŸºæœ¬åˆå§‹åŒ–å’Œé…ç½®
2. è¨“ç·´å¾ªç’°ä¸­çš„ä½¿ç”¨
3. è¨˜æ†¶é«”ä½¿ç”¨æ¯”è¼ƒ
4. é‚Šç·£æƒ…æ³æª¢æ¸¬å’Œè™•ç†
5. ç‹€æ…‹ä¿å­˜å’Œè¼‰å…¥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import time
import psutil
import os
from library.automagic_cameamp import Automagic_CameAMP_COptim, Automagic_CameAMP_COptim8bit

class AdvancedModel(nn.Module):
    """æ›´è¤‡é›œçš„æ¨¡å‹ç”¨æ–¼æ¸¬è©¦å„ªåŒ–å™¨æ€§èƒ½"""

    def __init__(self, input_size=784, hidden_sizes=[512, 256, 128], num_classes=10):
        super().__init__()

        layers = []
        prev_size = input_size

        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.BatchNorm1d(hidden_size),
                nn.ReLU(),
                nn.Dropout(0.2)
            ])
            prev_size = hidden_size

        layers.append(nn.Linear(prev_size, num_classes))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

def get_memory_usage():
    """ç²å–ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024

def create_synthetic_data(batch_size=64, input_size=784, num_classes=10):
    """å‰µå»ºåˆæˆæ•¸æ“šç”¨æ–¼æ¸¬è©¦"""
    x = torch.randn(batch_size, input_size)
    y = torch.randint(0, num_classes, (batch_size,))
    return x, y

def train_with_optimizer(model, optimizer, num_epochs=5, batch_size=64):
    """ä½¿ç”¨æŒ‡å®šå„ªåŒ–å™¨è¨“ç·´æ¨¡å‹"""
    model.train()
    device = next(model.parameters()).device

    print(f"\né–‹å§‹è¨“ç·´ - å„ªåŒ–å™¨: {optimizer.__class__.__name__}")
    print(f"è¨­å‚™: {device}")

    start_memory = get_memory_usage()
    start_time = time.time()

    losses = []

    for epoch in range(num_epochs):
        epoch_losses = []

        for step in range(20):  # æ¯å€‹ epoch 20 æ­¥
            # å‰µå»ºæ‰¹æ¬¡æ•¸æ“š
            x, y = create_synthetic_data(batch_size)
            x, y = x.to(device), y.to(device)

            # å‰å‘å‚³æ’­
            outputs = model(x)
            loss = F.cross_entropy(outputs, y)

            # åå‘å‚³æ’­
            optimizer.zero_grad()
            loss.backward()

            # å„ªåŒ–å™¨æ­¥é©Ÿ
            optimizer.step()

            epoch_losses.append(loss.item())

        avg_loss = sum(epoch_losses) / len(epoch_losses)
        losses.append(avg_loss)

        # æª¢æŸ¥ C-Optim ç‹€æ…‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(optimizer, 'c_optim'):
            edge_case = optimizer.c_optim.detect_edge_case()
            lr_multiplier = optimizer.c_optim.compute_contextual_lr_multiplier()
            print(f"Epoch {epoch+1}: Loss={avg_loss:.4f}, "
                  f"Edge Case={edge_case}, LR Multiplier={lr_multiplier:.4f}")
        else:
            print(f"Epoch {epoch+1}: Loss={avg_loss:.4f}")

    end_time = time.time()
    end_memory = get_memory_usage()

    print(f"è¨“ç·´å®Œæˆï¼")
    print(f"è¨“ç·´æ™‚é–“: {end_time - start_time:.2f} ç§’")
    print(f"è¨˜æ†¶é«”ä½¿ç”¨: {end_memory - start_memory:.2f} MB")
    print(f"æœ€çµ‚æå¤±: {losses[-1]:.4f}")

    return losses, end_memory - start_memory

def compare_optimizers():
    """æ¯”è¼ƒä¸åŒå„ªåŒ–å™¨çš„æ€§èƒ½"""
    print("=" * 60)
    print("Automagic_CameAMP_COptim vs Automagic_CameAMP_COptim8bit æ¯”è¼ƒ")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    # æ¸¬è©¦é…ç½®
    configs = [
        {
            'name': '32-bit C-Optim',
            'optimizer_class': Automagic_CameAMP_COptim,
            'kwargs': {
                'lr': 1e-3,
                'context_window': 50,
                'edge_threshold': 0.9,
                'adaptation_rate': 0.15,
                'momentum_scales': [1, 3, 7, 15]
            }
        },
        {
            'name': '8-bit C-Optim',
            'optimizer_class': Automagic_CameAMP_COptim8bit,
            'kwargs': {
                'lr': 1e-3,
                'context_window': 50,
                'edge_threshold': 0.9,
                'adaptation_rate': 0.15,
                'momentum_scales': [1, 3, 7, 15]
            }
        }
    ]

    results = {}

    for config in configs:
        print(f"\n{'='*40}")
        print(f"æ¸¬è©¦: {config['name']}")
        print(f"{'='*40}")

        # å‰µå»ºæ–°æ¨¡å‹
        model = AdvancedModel().to(device)

        # å‰µå»ºå„ªåŒ–å™¨
        try:
            optimizer = config['optimizer_class'](
                model.parameters(),
                **config['kwargs']
            )

            # è¨“ç·´
            losses, memory_usage = train_with_optimizer(model, optimizer)

            results[config['name']] = {
                'final_loss': losses[-1],
                'memory_usage': memory_usage,
                'losses': losses
            }

        except Exception as e:
            print(f"éŒ¯èª¤: {e}")
            results[config['name']] = {
                'error': str(e)
            }

    # é¡¯ç¤ºæ¯”è¼ƒçµæœ
    print(f"\n{'='*60}")
    print("æ¯”è¼ƒçµæœ")
    print(f"{'='*60}")

    for name, result in results.items():
        if 'error' in result:
            print(f"{name}: éŒ¯èª¤ - {result['error']}")
        else:
            print(f"{name}:")
            print(f"  æœ€çµ‚æå¤±: {result['final_loss']:.4f}")
            print(f"  è¨˜æ†¶é«”ä½¿ç”¨: {result['memory_usage']:.2f} MB")

    return results

def test_state_save_load():
    """æ¸¬è©¦ç‹€æ…‹ä¿å­˜å’Œè¼‰å…¥åŠŸèƒ½"""
    print(f"\n{'='*40}")
    print("æ¸¬è©¦ç‹€æ…‹ä¿å­˜å’Œè¼‰å…¥")
    print(f"{'='*40}")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = AdvancedModel().to(device)

    # å‰µå»º 8-bit C-Optim å„ªåŒ–å™¨
    optimizer = Automagic_CameAMP_COptim8bit(
        model.parameters(),
        lr=1e-3,
        context_window=30,
        edge_threshold=0.85
    )

    # è¨“ç·´å¹¾æ­¥
    print("è¨“ç·´å¹¾æ­¥ä»¥å»ºç«‹ç‹€æ…‹...")
    for step in range(5):
        x, y = create_synthetic_data()
        x, y = x.to(device), y.to(device)

        outputs = model(x)
        loss = F.cross_entropy(outputs, y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        print(f"Step {step+1}: Loss={loss.item():.4f}")

    # ä¿å­˜ç‹€æ…‹
    print("\nä¿å­˜å„ªåŒ–å™¨ç‹€æ…‹...")
    state_dict = optimizer.state_dict()
    torch.save(state_dict, 'optimizer_state.pth')

    # å‰µå»ºæ–°çš„å„ªåŒ–å™¨ä¸¦è¼‰å…¥ç‹€æ…‹
    print("å‰µå»ºæ–°å„ªåŒ–å™¨ä¸¦è¼‰å…¥ç‹€æ…‹...")
    new_optimizer = Automagic_CameAMP_COptim8bit(
        model.parameters(),
        lr=1e-3,
        context_window=30,
        edge_threshold=0.85
    )

    loaded_state = torch.load('optimizer_state.pth')
    new_optimizer.load_state_dict(loaded_state)

    print("ç‹€æ…‹è¼‰å…¥æˆåŠŸï¼")

    # æ¸…ç†
    if os.path.exists('optimizer_state.pth'):
        os.remove('optimizer_state.pth')

def demonstrate_edge_case_handling():
    """å±•ç¤ºé‚Šç·£æƒ…æ³æª¢æ¸¬å’Œè™•ç†"""
    print(f"\n{'='*40}")
    print("é‚Šç·£æƒ…æ³æª¢æ¸¬æ¼”ç¤º")
    print(f"{'='*40}")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = AdvancedModel().to(device)

    optimizer = Automagic_CameAMP_COptim8bit(
        model.parameters(),
        lr=1e-3,
        edge_threshold=0.7,  # è¼ƒä½çš„é–¾å€¼ï¼Œæ›´å®¹æ˜“è§¸ç™¼é‚Šç·£æƒ…æ³
        adaptation_rate=0.2
    )

    print("ç›£æ§é‚Šç·£æƒ…æ³æª¢æ¸¬...")

    for step in range(15):
        # å‰µå»ºä¸€äº›"å›°é›£"çš„æ•¸æ“šä¾†è§¸ç™¼é‚Šç·£æƒ…æ³
        if step > 5:
            # å¢åŠ å™ªéŸ³ä¾†æ¨¡æ“¬å›°é›£çš„å„ªåŒ–æƒ…æ³
            x, y = create_synthetic_data()
            x += torch.randn_like(x) * 0.5  # æ·»åŠ å™ªéŸ³
        else:
            x, y = create_synthetic_data()

        x, y = x.to(device), y.to(device)

        outputs = model(x)
        loss = F.cross_entropy(outputs, y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # æª¢æŸ¥é‚Šç·£æƒ…æ³
        is_edge = optimizer.c_optim.detect_edge_case()
        lr_mult = optimizer.c_optim.compute_contextual_lr_multiplier()

        status = "ğŸ”´ é‚Šç·£æƒ…æ³" if is_edge else "ğŸŸ¢ æ­£å¸¸"
        print(f"Step {step+1:2d}: Loss={loss.item():.4f}, "
              f"LRå€æ•¸={lr_mult:.3f}, ç‹€æ…‹={status}")

if __name__ == "__main__":
    print("Automagic_CameAMP_COptim8bit å„ªåŒ–å™¨æ¸¬è©¦")
    print("=" * 60)

    try:
        # 1. æ¯”è¼ƒå„ªåŒ–å™¨æ€§èƒ½
        results = compare_optimizers()

        # 2. æ¸¬è©¦ç‹€æ…‹ä¿å­˜è¼‰å…¥
        test_state_save_load()

        # 3. å±•ç¤ºé‚Šç·£æƒ…æ³è™•ç†
        demonstrate_edge_case_handling()

        print(f"\n{'='*60}")
        print("æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print(f"{'='*60}")

    except Exception as e:
        print(f"æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()