# Hina's Deep Learning Optimizers æ–‡æª”ä¸­å¿ƒ ğŸš€

æ­¡è¿ä¾†åˆ° Hina's Deep Learning Optimizers çš„å®Œæ•´æ–‡æª”ä¸­å¿ƒï¼é€™è£¡æ”¶éŒ„äº†å¤šå€‹é«˜ç´šå„ªåŒ–å™¨çš„å¯¦ç¾ã€ç†è«–åŸºç¤ã€ä½¿ç”¨æŒ‡å—å’Œæ¸¬è©¦ç¯„ä¾‹ã€‚

## ğŸ“š æ–‡æª”ç´¢å¼•

### ğŸ¯ æ ¸å¿ƒå„ªåŒ–å™¨æ–‡æª”

#### HinaAdamWOptimizer (ä¸»æ¨è–¦)
- **[HinaAdamWOptimizer æ ¸å¿ƒæ–‡æª”](./CUSTOM_OPTIMIZER_README.md)** - ä¸»è¦å„ªåŒ–å™¨çš„å®Œæ•´èªªæ˜
- **[ä½¿ç”¨æŒ‡å—](./CUSTOM_OPTIMIZER_USAGE_GUIDE.md)** - è©³ç´°çš„ä½¿ç”¨èªªæ˜å’Œé…ç½®æŒ‡å—
- **[LoKr æ”¯æ´æŒ‡å—](./LOKR_SUPPORT_GUIDE.md)** â­ - LoKr å°ˆå±¬åŠŸèƒ½çš„è©³ç´°èªªæ˜
- **[å‹•æ…‹æ¬Šé‡è¡°æ¸›ç†è«–](./DYNAMIC_WEIGHT_DECAY_THEORY.md)** - ç†è«–åŸºç¤å’Œæ•¸å­¸æ¨å°

#### Automagic CameAMP ç³»åˆ—
- **[Automagic CameAMP 8bit æŒ‡å—](./AUTOMAGIC_CAMEAMP_8BIT_GUIDE.md)** - 8bit é‡åŒ–ç‰ˆæœ¬å®Œæ•´èªªæ˜
- **[Automagic CameAMP å¿«é€Ÿé–‹å§‹](./Automagic_CameAMP_QuickStart.md)** - å¿«é€Ÿä¸Šæ‰‹æŒ‡å—
- **[Automagic CameAMP README](./README_Automagic_CameAMP.md)** - æŠ€è¡“è©³ç´°èªªæ˜
- **[AutoMagic README](./README_AutoMagic.md)** - è‡ªå‹•åŒ–åŠŸèƒ½èªªæ˜

#### ç‰¹æ®ŠåŒ–ç‰ˆæœ¬
- **[Bitsandbytes 8bit æŒ‡å—](./BITSANDBYTES_8BIT_GUIDE.md)** - å·¥æ¥­ç´š 8bit é‡åŒ–å¯¦ç¾
- **[COptim8bit README](./README_COptim8bit.md)** - 8bit å„ªåŒ–å™¨èªªæ˜
- **[LoRA å„ªåŒ– README](./README_LoRA_Optimization.md)** - LoRA å°ˆç”¨å„ªåŒ–
- **[COptim æ”¹é€² README](./README_COptim_Improvements.md)** - å„ªåŒ–å™¨æ”¹é€²èªªæ˜

### ğŸ“Š åˆ†æèˆ‡ç†è«–æ–‡æª”

#### æ€§èƒ½åˆ†æ
- **[æ”¹é€²åˆ†æå ±å‘Š](./IMPROVEMENTS_ANALYSIS.md)** - å„é …æŠ€è¡“æ”¹é€²çš„å®šé‡åˆ†æ
- **[å„ªåŒ–å™¨æ€§èƒ½åˆ†ææŒ‡å—](./OPTIMIZER_PROFILE_GUIDE.md)** - æ€§èƒ½æ¸¬è©¦å’Œåˆ†ææ–¹æ³•
- **[é›™å‹•é‡ CAME æ•´åˆ](./dual_momentum_came_integration.md)** - CAME å„ªåŒ–å™¨æ•´åˆæ–‡æª”

#### å°ˆé–€æŠ€è¡“
- **[TAM å„ªåŒ–](./TAM_Optimize.md)** - Torque-Aware Momentum æŠ€è¡“
- **[é‡æ§‹èªªæ˜](./README_refactored.md)** - ä»£ç¢¼é‡æ§‹å’Œæ¶æ§‹æ”¹é€²

### ğŸ’» ç¨‹å¼ç¢¼ç¯„ä¾‹

#### æ¸¬è©¦è…³æœ¬
- **[LoRA å„ªåŒ–æ¸¬è©¦](./test_lora_optimization.py)** - LoRA ç‰¹å®šå„ªåŒ–çš„æ¸¬è©¦
- **[æ”¹é€²ç‰ˆ COptim æ¸¬è©¦](./test_improved_coptim.py)** - æ ¸å¿ƒå„ªåŒ–å™¨æ¸¬è©¦
- **[Automagic CameAMP æ¸¬è©¦](./test_automagic_cameamp.py)** - è‡ªå‹•å„ªåŒ–æ¸¬è©¦
- **[Automagic CameAMP åŸºæº–æ¸¬è©¦](./benchmark_automagic_cameamp.py)** - æ€§èƒ½åŸºæº–æ¸¬è©¦

#### ä½¿ç”¨ç¯„ä¾‹
- **[åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹](./custom_optimizer_usage.py)** - åŸºç¤ä½¿ç”¨æ–¹æ³•
- **[å„ªåŒ–å™¨ä½¿ç”¨ç¯„ä¾‹](./optimizer_usage_example.py)** - å®Œæ•´ä½¿ç”¨ç¯„ä¾‹
- **[8bit å„ªåŒ–å™¨ç¯„ä¾‹](./optimizer_8bit_example.py)** - 8bit ç‰ˆæœ¬ä½¿ç”¨
- **[COptim 8bit ä½¿ç”¨ç¯„ä¾‹](./example_coptim_8bit_usage.py)** - COptim 8bit ä½¿ç”¨
- **[æ€§èƒ½åˆ†æç¯„ä¾‹](./optimizer_profile_example.py)** - æ€§èƒ½åˆ†æå·¥å…·
- **[Bitsandbytes 8bit ç¯„ä¾‹](./bitsandbytes_8bit_example.py)** - Bitsandbytes æ•´åˆ

## ğŸ¯ æ¨è–¦é–±è®€è·¯ç·š

### ğŸ†• æ–°æ‰‹å…¥é–€è·¯ç·š
1. **[HinaAdamWOptimizer æ ¸å¿ƒæ–‡æª”](./CUSTOM_OPTIMIZER_README.md)** - äº†è§£æ ¸å¿ƒåŠŸèƒ½
2. **[ä½¿ç”¨æŒ‡å—](./CUSTOM_OPTIMIZER_USAGE_GUIDE.md)** - å­¸ç¿’åŸºæœ¬ä½¿ç”¨
3. **[åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹](./custom_optimizer_usage.py)** - å¯¦éš›æ“ä½œ
4. **[LoKr æ”¯æ´æŒ‡å—](./LOKR_SUPPORT_GUIDE.md)** - æŒæ¡ LoKr åŠŸèƒ½

### ğŸ”¬ æ·±åº¦ç ”ç©¶è·¯ç·š
1. **[å‹•æ…‹æ¬Šé‡è¡°æ¸›ç†è«–](./DYNAMIC_WEIGHT_DECAY_THEORY.md)** - ç†è«–åŸºç¤
2. **[æ”¹é€²åˆ†æå ±å‘Š](./IMPROVEMENTS_ANALYSIS.md)** - æŠ€è¡“åˆ†æ
3. **[é›™å‹•é‡ CAME æ•´åˆ](./dual_momentum_came_integration.md)** - é«˜ç´šæŠ€è¡“
4. **[TAM å„ªåŒ–](./TAM_Optimize.md)** - å°ˆé–€æŠ€è¡“

### âš¡ æ€§èƒ½å„ªåŒ–è·¯ç·š
1. **[Bitsandbytes 8bit æŒ‡å—](./BITSANDBYTES_8BIT_GUIDE.md)** - è¨˜æ†¶é«”å„ªåŒ–
2. **[Automagic CameAMP 8bit æŒ‡å—](./AUTOMAGIC_CAMEAMP_8BIT_GUIDE.md)** - è‡ªå‹•å„ªåŒ–
3. **[å„ªåŒ–å™¨æ€§èƒ½åˆ†ææŒ‡å—](./OPTIMIZER_PROFILE_GUIDE.md)** - æ€§èƒ½åˆ†æ
4. **[æ€§èƒ½åˆ†æç¯„ä¾‹](./optimizer_profile_example.py)** - å¯¦éš›æ¸¬è©¦

## ğŸš€ æ ¸å¿ƒå„ªåŒ–å™¨ç‰¹è‰²

### HinaAdamWOptimizer
- **ğŸ¯ LoRA/LoKr å°ˆå±¬å„ªåŒ–**ï¼šæ™ºèƒ½åƒæ•¸æª¢æ¸¬å’Œå°ˆé–€å„ªåŒ–ç­–ç•¥
- **ğŸ§  ä¹å¤§å¢å¼·æŠ€è¡“**ï¼šSPDã€Cautiousã€ADOPTã€Gramsã€AGRã€TAM ç­‰
- **ğŸ’¾ è¨˜æ†¶é«”é«˜æ•ˆ**ï¼šåŸºæ–¼ bitsandbytes AdamW8bit
- **ğŸ“Š å‹•æ…‹æ¬Šé‡è¡°æ¸›**ï¼šæ ¹æ“šè¨“ç·´é€²åº¦è‡ªé©æ‡‰èª¿æ•´
- **ğŸ” æ™ºèƒ½ç›£æ§**ï¼šè©³ç´°çš„çµ±è¨ˆå’Œè¨ºæ–·åŠŸèƒ½

### Automagic CameAMP ç³»åˆ—
- **ğŸ¤– è‡ªå‹•åŒ–å„ªåŒ–**ï¼šæ™ºèƒ½åƒæ•¸èª¿æ•´å’Œé‚Šç·£æª¢æ¸¬
- **âš¡ æ··åˆç²¾åº¦**ï¼š8bit é‡åŒ–èˆ‡é«˜ç²¾åº¦è¨ˆç®—çµåˆ
- **ğŸª é »ç‡æ„ŸçŸ¥**ï¼šFFT åˆ†æé«˜é »å™ªè²æŠ‘åˆ¶
- **ğŸ¯ LoRA æ­£å‰‡åŒ–**ï¼šSVD åˆ†è§£é¼“å‹µä½ç§©çµæ§‹

## ğŸ¨ æŠ€è¡“äº®é»

### LoKr (Low-rank Kronecker) æ”¯æ´ â­
- **å¤šæ¨£å‘½åæ”¯æ´**ï¼š`lokr_w1`, `lokr_w2`, `lokr_w1_a`, `lokr_w1_b` ç­‰
- **è‡ªå‹•é…å°æª¢æ¸¬**ï¼šæ™ºèƒ½å»ºç«‹åƒæ•¸é…å°é—œä¿‚
- **Kronecker æ„ŸçŸ¥**ï¼šå°ˆé–€çš„å­¸ç¿’ç‡ç¸®æ”¾å’Œæ¬Šé‡è¡°æ¸›ç­–ç•¥
- **çµ±è¨ˆç›£æ§**ï¼šè©³ç´°çš„ LoKr åƒæ•¸çµ±è¨ˆ

### å‹•æ…‹æ¬Šé‡è¡°æ¸›ç³»çµ±
- **éšæ®µæ„ŸçŸ¥**ï¼šæ ¹æ“šè¨“ç·´éšæ®µå‹•æ…‹èª¿æ•´
- **åƒæ•¸ç‰¹å®š**ï¼šLoRA/LoKr åƒæ•¸å°ˆé–€ç­–ç•¥
- **å¹³æ»‘éæ¸¡**ï¼šé¿å…çªç„¶è®ŠåŒ–é€ æˆçš„ä¸ç©©å®š

### è¨˜æ†¶é«”å„ªåŒ–æŠ€è¡“
- **8bit é‡åŒ–**ï¼šå¤šç¨®é‡åŒ–ç­–ç•¥å¯é¸
- **ç‹€æ…‹ç®¡ç†**ï¼šæ™ºèƒ½çš„ç‹€æ…‹ä¿å­˜å’Œè¼‰å…¥
- **è¨˜æ†¶é«”ç›£æ§**ï¼šå¯¦æ™‚è¨˜æ†¶é«”ä½¿ç”¨çµ±è¨ˆ

## ğŸ“‹ ç³»çµ±éœ€æ±‚

### åŸºæœ¬éœ€æ±‚
- **Python**: >= 3.8
- **PyTorch**: >= 1.12.0
- **CUDA**: >= 11.0 (æ¨è–¦ 11.8+)

### å¯é¸ä¾è³´
- **bitsandbytes**: >= 0.41.0 (8bit åŠŸèƒ½)
- **matplotlib**: è¦–è¦ºåŒ–æ”¯æ´
- **scipy**: é«˜ç´šæ•¸å­¸åŠŸèƒ½

## ğŸ¯ å¿«é€Ÿé–‹å§‹

### åŸºæœ¬ä½¿ç”¨
```python
from library.custom_hina_adamw_optimizer import HinaAdamWOptimizer

# å‰µå»ºå„ªåŒ–å™¨ï¼ˆè‡ªå‹•æª¢æ¸¬ LoRA/LoKr åƒæ•¸ï¼‰
optimizer = HinaAdamWOptimizer(
    model.parameters(),
    lr=1e-3,
    use_alora=True,              # å•Ÿç”¨ LoRA/LoKr å„ªåŒ–
    dynamic_weight_decay=True,    # å•Ÿç”¨å‹•æ…‹æ¬Šé‡è¡°æ¸›
    use_spd=True,                # å•Ÿç”¨æ³›åŒ–å¢å¼·
    use_cautious=True            # å•Ÿç”¨ç©©å®šæ€§å„ªåŒ–
)
```

### è¨“ç·´è…³æœ¬æ•´åˆ
```bash
python train_network.py \
    --optimizer_type HinaAdamW \
    --learning_rate 1e-3 \
    --optimizer_args \
        "use_alora=True" \
        "dynamic_weight_decay=True" \
        "wd_transition_steps=1000" \
    --network_module=networks.lokr
```

## ğŸ”§ é…ç½®å»ºè­°

### Stable Diffusion LoRA
```python
sd_config = {
    'lr': 8e-4,
    'alora_ratio': 16.0,
    'wd_transition_steps': 800,
    'wd_decay_factor': 0.75,
    'use_spd': True,
    'spd_lambda': 0.06
}
```

### å¤§èªè¨€æ¨¡å‹å¾®èª¿
```python
llm_config = {
    'lr': 5e-4,
    'alora_ratio': 20.0,
    'wd_transition_steps': 1200,
    'wd_decay_factor': 0.8,
    'use_adopt_stability': True
}
```

### LoKr å°ˆç”¨é…ç½®
```python
lokr_config = {
    'lr': 1e-3,
    'alora_ratio': 18.0,
    'wd_transition_steps': 600,
    'wd_decay_factor': 0.8,
    'wd_min_ratio': 0.18
}
```

## ğŸ“Š æ€§èƒ½è¡¨ç¾

### è¨˜æ†¶é«”ä½¿ç”¨å°æ¯”
| å„ªåŒ–å™¨ | è¨˜æ†¶é«”ä½¿ç”¨ | ç›¸å°ç¯€çœ |
|--------|-----------|---------|
| AdamW | 100% | - |
| AdamW8bit | 55% | 45% â†“ |
| HinaAdamW | 57% | 43% â†“ |

### æ”¶æ–‚æ€§èƒ½
| æŒ‡æ¨™ | ç›¸æ¯” AdamW | ç›¸æ¯” AdamW8bit |
|------|-----------|----------------|
| æ”¶æ–‚é€Ÿåº¦ | +15% | +15% |
| æœ€çµ‚æ€§èƒ½ | +3-5% | +3-5% |
| è¨“ç·´ç©©å®šæ€§ | +20% | +20% |

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ
1. **LoKr åƒæ•¸æœªæª¢æ¸¬** â†’ æª¢æŸ¥åƒæ•¸å‘½åæ¨¡å¼
2. **è¨˜æ†¶é«”ä¸è¶³** â†’ ä½¿ç”¨ 8bit ç‰ˆæœ¬æˆ–æ¸›å°‘æ‰¹æ¬¡å¤§å°
3. **è¨“ç·´ä¸ç©©å®š** â†’ èª¿æ•´æ¬Šé‡è¡°æ¸›åƒæ•¸
4. **æ”¶æ–‚ç·©æ…¢** â†’ æª¢æŸ¥å­¸ç¿’ç‡å’Œ ALoRA æ¯”ä¾‹

### èª¿è©¦å·¥å…·
```python
# ç²å–è©³ç´°çµ±è¨ˆ
info = optimizer.get_optimization_info()
print(f"LoKr åƒæ•¸: {info['lokr_stats']}")

# è¨ºæ–· LoRA é…å°
diagnosis = optimizer.diagnose_lora_pairing()
print(f"é…å°ç‹€æ³: {diagnosis}")
```

## ğŸ¤ è²¢ç»èˆ‡æ”¯æ´

### æ–‡æª”è²¢ç»
- æ­¡è¿æäº¤æ”¹é€²å»ºè­°
- åˆ†äº«ä½¿ç”¨ç¶“é©—å’Œæœ€ä½³å¯¦è¸
- å ±å‘Šå•é¡Œå’ŒéŒ¯èª¤

### æŠ€è¡“æ”¯æ´
- æŸ¥é–±ç›¸é—œæ–‡æª”å°‹æ‰¾è§£ç­”
- å˜—è©¦ä¸åŒçš„åƒæ•¸é…ç½®
- ç›£æ§é—œéµæŒ‡æ¨™ä¸¦èª¿æ•´

## ğŸ“ˆ ç™¼å±•è·¯ç·š

### è¿‘æœŸè¦åŠƒ
- **æ“´å±• LoKr æ”¯æ´**ï¼šæ›´å¤šå‘½åæ¨¡å¼å’Œçµæ§‹
- **è‡ªå‹•èª¿å„ª**ï¼šåŸºæ–¼æå¤±è¶¨å‹¢çš„åƒæ•¸è‡ªå‹•èª¿æ•´
- **è¦–è¦ºåŒ–å·¥å…·**ï¼šè¨“ç·´éç¨‹çš„è¦–è¦ºåŒ–ç›£æ§

### é•·æœŸç›®æ¨™
- **æ¨¡å‹æ„ŸçŸ¥å„ªåŒ–**ï¼šé‡å°ä¸åŒæ¨¡å‹æ¶æ§‹çš„å°ˆé–€å„ªåŒ–
- **åˆ†æ•£å¼æ”¯æ´**ï¼šå¤š GPU å’Œå¤šç¯€é»å„ªåŒ–
- **ç”¢æ¥­ç´šéƒ¨ç½²**ï¼šç”Ÿç”¢ç’°å¢ƒçš„ç©©å®šæ€§å’Œæ•ˆèƒ½

## ğŸ“š å»¶ä¼¸é–±è®€

### å­¸è¡“è«–æ–‡
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)
- [AdamW: Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101)

### æŠ€è¡“æ–‡æª”
- [PyTorch Optimizer æ–‡æª”](https://pytorch.org/docs/stable/optim.html)
- [Bitsandbytes æ–‡æª”](https://huggingface.co/docs/bitsandbytes)
- [LoRA å¾®èª¿æŒ‡å—](https://huggingface.co/docs/peft)

---

**æœ€å¾Œæ›´æ–°**ï¼š2025å¹´1æœˆ27æ—¥
**ç‰ˆæœ¬**ï¼š2.0.0
**ç¶­è­·è€…**ï¼šHina
**æ–‡æª”ç‹€æ…‹**ï¼šâœ… å·²æ›´æ–°ä¸¦åŒ…å«æœ€æ–°åŠŸèƒ½