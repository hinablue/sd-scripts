#!/usr/bin/env python3
"""
HinaAdaptive æ­£å‰‡åŒ–æŠ€è¡“ç¶­åº¦è™•ç†æ¸¬è©¦

æ¸¬è©¦ä¸åŒå½¢ç‹€çš„å¼µé‡æ˜¯å¦èƒ½æ­£ç¢ºè™•ç†å„ç¨®æ­£å‰‡åŒ–æŠ€è¡“ï¼Œç¢ºä¿æ²’æœ‰ç¶­åº¦ä¸åŒ¹é…éŒ¯èª¤ã€‚

æ³¨æ„ï¼šå‚…ç«‹è‘‰ç‰¹å¾µæå¤±åŠŸèƒ½å·²è¢«ç§»é™¤ï¼Œå› ç‚ºå®ƒä¸é©ç”¨æ–¼ SD-Scripts
çš„ latent space è¨“ç·´ç’°å¢ƒã€‚
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ åº«è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from library.hina_adaptive import HinaAdaptive

def test_regularization_dimensions():
    """æ¸¬è©¦æ­£å‰‡åŒ–æŠ€è¡“çš„ç¶­åº¦è™•ç†"""
    print("=" * 60)
    print("æ¸¬è©¦æ­£å‰‡åŒ–æŠ€è¡“ç¶­åº¦è™•ç†")
    print("=" * 60)

    # å‰µå»ºå„ç¨®å½¢ç‹€çš„æ¸¬è©¦å¼µé‡
    test_shapes = [
        (8, 8),           # 2D: å…¨é€£æ¥å±¤æ¬Šé‡
        (1, 8, 8),        # 3D: å–®é€šé“å·ç©
        (64, 32, 3, 3),   # 4D: 2Då·ç©æ¬Šé‡
        (128, 64, 5, 5),  # 4D: è¼ƒå¤§çš„å·ç©æ ¸
        (256, 128, 7, 7), # 4D: æ›´å¤§çš„å·ç©æ ¸
        (16, 32, 1, 1),   # 4D: 1x1å·ç©
        (32, 16, 3, 3, 3), # 5D: 3Då·ç©æ¬Šé‡
    ]

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    all_tests_passed = True

    for i, shape in enumerate(test_shapes):
        print(f"\næ¸¬è©¦ {i+1}/{len(test_shapes)}: å½¢ç‹€ {shape}")
        print("-" * 40)

        try:
            # å‰µå»ºæ¸¬è©¦åƒæ•¸
            param = torch.randn(shape, device=device, requires_grad=True)

            # å‰µå»ºå„ªåŒ–å™¨ï¼Œå•Ÿç”¨å„ç¨®æ­£å‰‡åŒ–æŠ€è¡“
            optimizer = HinaAdaptive(
                [param],
                lr=1e-3,
                # å„ç¨®æ­£å‰‡åŒ–æŠ€è¡“
                edge_suppression=True,
                edge_penalty=0.1,
                spatial_awareness=True,
                frequency_penalty=0.05,
                background_regularization=True,
                lora_rank_penalty=True,
                rank_penalty_strength=0.01,
                # è¨˜æ†¶é«”å„ªåŒ–
                memory_efficient=True,
                vram_budget_gb=8.0
            )

            # å‰µå»ºå°æ‡‰çš„ç›®æ¨™å¼µé‡
            target = torch.randn_like(param)

            # æ¨¡æ“¬å‰å‘å‚³æ’­
            output = param * 2.0  # ç°¡å–®æ“ä½œ
            loss = torch.nn.functional.mse_loss(output, target)

            # æ¸¬è©¦åå‘å‚³æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"âœ… å½¢ç‹€ {shape} è™•ç†æˆåŠŸ")
            print(f"   - åƒæ•¸å…ƒç´ æ•¸é‡: {param.numel()}")
            print(f"   - æ¢¯åº¦ç¯„æ•¸: {torch.norm(param.grad).item():.6f}")
            print(f"   - æå¤±å€¼: {loss.item():.6f}")

            # é©—è­‰å„ªåŒ–å™¨ç‹€æ…‹
            info = optimizer.get_optimization_info()
            print(f"   - å•Ÿç”¨çš„æ­£å‰‡åŒ–æŠ€è¡“: {sum(info['features'].values())}")

        except Exception as e:
            print(f"âŒ å½¢ç‹€ {shape} è™•ç†å¤±æ•—: {e}")
            all_tests_passed = False

    return all_tests_passed

def test_edge_suppression_dimensions():
    """æ¸¬è©¦é‚Šç·£æ„ŸçŸ¥æ­£å‰‡åŒ–çš„ç¶­åº¦è™•ç†"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦é‚Šç·£æ„ŸçŸ¥æ­£å‰‡åŒ–ç¶­åº¦è™•ç†")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æ¸¬è©¦ä¸åŒç¶­åº¦çš„å·ç©å±¤
    test_cases = [
        ("2Då·ç©", nn.Conv2d(3, 16, 3, padding=1)),
        ("å¤§å·ç©æ ¸", nn.Conv2d(16, 32, 7, padding=3)),
        ("1x1å·ç©", nn.Conv2d(32, 64, 1)),
        ("æ·±åº¦å·ç©", nn.Conv2d(64, 128, 5, padding=2)),
    ]

    all_tests_passed = True

    for name, layer in test_cases:
        print(f"\næ¸¬è©¦ {name}:")
        print("-" * 30)

        try:
            layer = layer.to(device)

            # å‰µå»ºé‚Šç·£æ„ŸçŸ¥å„ªåŒ–å™¨
            optimizer = HinaAdaptive(
                layer.parameters(),
                lr=1e-3,
                edge_suppression=True,
                edge_penalty=0.1,
                edge_threshold=0.6,
                memory_efficient=True
            )

            # å‰µå»ºæ¸¬è©¦æ•¸æ“š
            if isinstance(layer, nn.Conv2d):
                x = torch.randn(2, layer.in_channels, 32, 32, device=device)
            else:
                x = torch.randn(2, layer.in_channels, 32, 32, device=device)

            # å‰å‘å‚³æ’­
            output = layer(x)
            loss = torch.mean(output ** 2)

            # åå‘å‚³æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"âœ… {name} è™•ç†æˆåŠŸ")
            print(f"   - æ¬Šé‡å½¢ç‹€: {layer.weight.shape}")
            print(f"   - æ¢¯åº¦ç¯„æ•¸: {torch.norm(layer.weight.grad).item():.6f}")

        except Exception as e:
            print(f"âŒ {name} è™•ç†å¤±æ•—: {e}")
            all_tests_passed = False

    return all_tests_passed

def test_spatial_awareness_dimensions():
    """æ¸¬è©¦ç©ºé–“æ„ŸçŸ¥æ­£å‰‡åŒ–çš„ç¶­åº¦è™•ç†"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ç©ºé–“æ„ŸçŸ¥æ­£å‰‡åŒ–ç¶­åº¦è™•ç†")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æ¸¬è©¦ä¸åŒå¤§å°çš„ç‰¹å¾µåœ–
    test_sizes = [
        (8, 8),     # å°ç‰¹å¾µåœ–
        (32, 32),   # ä¸­ç­‰ç‰¹å¾µåœ–
        (64, 64),   # å¤§ç‰¹å¾µåœ–
        (128, 128), # å¾ˆå¤§ç‰¹å¾µåœ–
    ]

    all_tests_passed = True

    for size in test_sizes:
        print(f"\næ¸¬è©¦ç‰¹å¾µåœ–å¤§å° {size}:")
        print("-" * 30)

        try:
            # å‰µå»ºå°æ‡‰å¤§å°çš„å·ç©å±¤
            layer = nn.Conv2d(3, 16, 3, padding=1).to(device)

            # å‰µå»ºç©ºé–“æ„ŸçŸ¥å„ªåŒ–å™¨
            optimizer = HinaAdaptive(
                layer.parameters(),
                lr=1e-3,
                spatial_awareness=True,
                frequency_penalty=0.05,
                detail_preservation=0.8,
                memory_efficient=True
            )

            # å‰µå»ºæ¸¬è©¦æ•¸æ“š
            x = torch.randn(1, 3, size[0], size[1], device=device)

            # å‰å‘å‚³æ’­
            output = layer(x)
            loss = torch.mean(output ** 2)

            # åå‘å‚³æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"âœ… ç‰¹å¾µåœ–å¤§å° {size} è™•ç†æˆåŠŸ")
            print(f"   - è¼¸å…¥å½¢ç‹€: {x.shape}")
            print(f"   - è¼¸å‡ºå½¢ç‹€: {output.shape}")
            print(f"   - æå¤±å€¼: {loss.item():.6f}")

        except Exception as e:
            print(f"âŒ ç‰¹å¾µåœ–å¤§å° {size} è™•ç†å¤±æ•—: {e}")
            all_tests_passed = False

    return all_tests_passed

def test_lora_regularization_dimensions():
    """æ¸¬è©¦ LoRA ä½ç§©æ­£å‰‡åŒ–çš„ç¶­åº¦è™•ç†"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ LoRA ä½ç§©æ­£å‰‡åŒ–ç¶­åº¦è™•ç†")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æ¸¬è©¦ä¸åŒå¤§å°çš„çŸ©é™£
    test_matrices = [
        (64, 32),    # å°çŸ©é™£
        (128, 64),   # ä¸­ç­‰çŸ©é™£
        (256, 128),  # å¤§çŸ©é™£
        (512, 256),  # å¾ˆå¤§çŸ©é™£
        (32, 128),   # å¯¬çŸ©é™£
        (128, 32),   # çª„çŸ©é™£
    ]

    all_tests_passed = True

    for rows, cols in test_matrices:
        print(f"\næ¸¬è©¦çŸ©é™£å¤§å° {rows}x{cols}:")
        print("-" * 30)

        try:
            # å‰µå»ºç·šæ€§å±¤
            layer = nn.Linear(cols, rows).to(device)

            # å‰µå»º LoRA ä½ç§©æ­£å‰‡åŒ–å„ªåŒ–å™¨
            optimizer = HinaAdaptive(
                layer.parameters(),
                lr=1e-3,
                lora_rank_penalty=True,
                rank_penalty_strength=0.01,
                low_rank_emphasis=1.2,
                memory_efficient=True
            )

            # å‰µå»ºæ¸¬è©¦æ•¸æ“š
            x = torch.randn(8, cols, device=device)

            # å‰å‘å‚³æ’­
            output = layer(x)
            loss = torch.mean(output ** 2)

            # åå‘å‚³æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"âœ… çŸ©é™£å¤§å° {rows}x{cols} è™•ç†æˆåŠŸ")
            print(f"   - æ¬Šé‡å½¢ç‹€: {layer.weight.shape}")
            print(f"   - æ¬Šé‡ç§©ä¼°è¨ˆ: {torch.linalg.matrix_rank(layer.weight.data).item()}")
            print(f"   - æå¤±å€¼: {loss.item():.6f}")

        except Exception as e:
            print(f"âŒ çŸ©é™£å¤§å° {rows}x{cols} è™•ç†å¤±æ•—: {e}")
            all_tests_passed = False

    return all_tests_passed

def test_background_regularization_dimensions():
    """æ¸¬è©¦èƒŒæ™¯æ­£å‰‡åŒ–çš„ç¶­åº¦è™•ç†"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦èƒŒæ™¯æ­£å‰‡åŒ–ç¶­åº¦è™•ç†")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # æ¸¬è©¦ä¸åŒå½¢ç‹€çš„å¼µé‡
    test_shapes = [
        (1, 16, 16),      # 3Då¼µé‡
        (3, 32, 32),      # RGBåœ–åƒ
        (64, 64, 64),     # é«”ç©æ•¸æ“š
        (16, 128, 128),   # é«˜è§£æåº¦
    ]

    all_tests_passed = True

    for shape in test_shapes:
        print(f"\næ¸¬è©¦å¼µé‡å½¢ç‹€ {shape}:")
        print("-" * 30)

        try:
            # å‰µå»ºå·ç©å±¤
            if len(shape) == 3:
                layer = nn.Conv2d(shape[0], 16, 3, padding=1).to(device)
            else:
                layer = nn.Conv2d(shape[0], 16, 3, padding=1).to(device)

            # å‰µå»ºèƒŒæ™¯æ­£å‰‡åŒ–å„ªåŒ–å™¨
            optimizer = HinaAdaptive(
                layer.parameters(),
                lr=1e-3,
                background_regularization=True,
                memory_efficient=True
            )

            # å‰µå»ºæ¸¬è©¦æ•¸æ“š
            x = torch.randn(1, *shape, device=device)

            # å‰å‘å‚³æ’­
            output = layer(x)
            loss = torch.mean(output ** 2)

            # åå‘å‚³æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"âœ… å¼µé‡å½¢ç‹€ {shape} è™•ç†æˆåŠŸ")
            print(f"   - è¼¸å…¥å½¢ç‹€: {x.shape}")
            print(f"   - è¼¸å‡ºå½¢ç‹€: {output.shape}")
            print(f"   - æå¤±å€¼: {loss.item():.6f}")

        except Exception as e:
            print(f"âŒ å¼µé‡å½¢ç‹€ {shape} è™•ç†å¤±æ•—: {e}")
            all_tests_passed = False

    return all_tests_passed

def test_combined_regularization_dimensions():
    """æ¸¬è©¦çµ„åˆæ­£å‰‡åŒ–æŠ€è¡“çš„ç¶­åº¦è™•ç†"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦çµ„åˆæ­£å‰‡åŒ–æŠ€è¡“ç¶­åº¦è™•ç†")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # å‰µå»ºè¤‡é›œçš„æ¨¡å‹
    class TestModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
            self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
            self.linear1 = nn.Linear(128 * 8 * 8, 256)
            self.linear2 = nn.Linear(256, 10)

        def forward(self, x):
            x = torch.relu(self.conv1(x))
            x = torch.relu(self.conv2(x))
            x = torch.relu(self.conv3(x))
            x = torch.adaptive_avg_pool2d(x, (8, 8))
            x = x.view(x.size(0), -1)
            x = torch.relu(self.linear1(x))
            x = self.linear2(x)
            return x

    try:
        model = TestModel().to(device)

        # å‰µå»ºçµ„åˆæ­£å‰‡åŒ–å„ªåŒ–å™¨
        optimizer = HinaAdaptive(
            model.parameters(),
            lr=1e-3,
            # çµ„åˆæ‰€æœ‰æ­£å‰‡åŒ–æŠ€è¡“
            edge_suppression=True,
            edge_penalty=0.1,
            spatial_awareness=True,
            frequency_penalty=0.05,
            background_regularization=True,
            lora_rank_penalty=True,
            rank_penalty_strength=0.01,
            # å…¶ä»–åŠŸèƒ½
            use_dynamic_adaptation=True,
            memory_efficient=True,
            vram_budget_gb=8.0
        )

        # å‰µå»ºæ¸¬è©¦æ•¸æ“š
        x = torch.randn(4, 3, 32, 32, device=device)
        y = torch.randn(4, 10, device=device)

        # è¨“ç·´å¹¾æ­¥
        for step in range(5):
            optimizer.zero_grad()
            output = model(x)
            loss = torch.nn.functional.mse_loss(output, y)
            loss.backward()
            optimizer.step()

            print(f"æ­¥é©Ÿ {step+1}: æå¤± = {loss.item():.6f}")

        print("âœ… çµ„åˆæ­£å‰‡åŒ–æŠ€è¡“ç¶­åº¦è™•ç†æˆåŠŸ")
        return True

    except Exception as e:
        print(f"âŒ çµ„åˆæ­£å‰‡åŒ–æŠ€è¡“ç¶­åº¦è™•ç†å¤±æ•—: {e}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” HinaAdaptive æ­£å‰‡åŒ–æŠ€è¡“ç¶­åº¦è™•ç†æ¸¬è©¦")
    print("=" * 60)

    tests = [
        ("åŸºæœ¬æ­£å‰‡åŒ–ç¶­åº¦è™•ç†", test_regularization_dimensions),
        ("é‚Šç·£æ„ŸçŸ¥æ­£å‰‡åŒ–ç¶­åº¦è™•ç†", test_edge_suppression_dimensions),
        ("ç©ºé–“æ„ŸçŸ¥æ­£å‰‡åŒ–ç¶­åº¦è™•ç†", test_spatial_awareness_dimensions),
        ("LoRA ä½ç§©æ­£å‰‡åŒ–ç¶­åº¦è™•ç†", test_lora_regularization_dimensions),
        ("èƒŒæ™¯æ­£å‰‡åŒ–ç¶­åº¦è™•ç†", test_background_regularization_dimensions),
        ("çµ„åˆæ­£å‰‡åŒ–ç¶­åº¦è™•ç†", test_combined_regularization_dimensions),
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        print(f"\nğŸ§ª åŸ·è¡Œ {test_name}...")
        try:
            if test_func():
                print(f"âœ… {test_name} é€šé")
                passed += 1
            else:
                print(f"âŒ {test_name} å¤±æ•—")
        except Exception as e:
            print(f"âŒ {test_name} ç•°å¸¸: {e}")

    # ç¸½çµçµæœ
    print("\n" + "=" * 60)
    print(f"ğŸ“Š æ¸¬è©¦çµæœ: {passed}/{total} é€šé")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰ç¶­åº¦è™•ç†æ¸¬è©¦é€šéï¼")
        print("âœ… å„ç¨®æ­£å‰‡åŒ–æŠ€è¡“éƒ½èƒ½æ­£ç¢ºè™•ç†ä¸åŒå½¢ç‹€çš„å¼µé‡")
    else:
        print(f"âš ï¸  {total - passed} å€‹æ¸¬è©¦å¤±æ•—")
        print("âŒ æŸäº›æ­£å‰‡åŒ–æŠ€è¡“å¯èƒ½å­˜åœ¨ç¶­åº¦è™•ç†å•é¡Œ")

    return passed == total

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâš ï¸  æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)