# æ•´åˆå‹å‚…ç«‹è‘‰æå¤±å®Œæ•´æŒ‡å—
# Unified Fourier Loss Complete Guide

## ğŸŒŸ æ¦‚è¿° Overview

æ•´åˆå‹å‚…ç«‹è‘‰æå¤±æ˜¯ sd-scripts é …ç›®çš„æœ€æ–°å‰µæ–°åŠŸèƒ½ï¼Œå°‡å¤šå°ºåº¦ã€é »ç‡åŠ æ¬Šå’Œè‡ªé©æ‡‰ä¸‰ç¨®ç­–ç•¥å·§å¦™çµåˆï¼Œæä¾›æ›´å¼·å¤§å’Œéˆæ´»çš„æå¤±è¨ˆç®—èƒ½åŠ›ã€‚æœ¬æŒ‡å—å°‡å…¨é¢ä»‹ç´¹é€™ä¸€é©å‘½æ€§åŠŸèƒ½çš„ä½¿ç”¨æ–¹æ³•ã€é…ç½®æŠ€å·§å’Œæœ€ä½³å¯¦è¸ã€‚

The Unified Fourier Loss is the latest innovative feature in the sd-scripts project, cleverly combining multiscale, frequency weighting, and adaptive strategies to provide more powerful and flexible loss computation capabilities.

## ğŸ—ï¸ æ¶æ§‹è¨­è¨ˆ Architecture Design

### æ ¸å¿ƒç†å¿µ Core Philosophy
```
æ•´åˆæå¤± = å‹•æ…‹æ¬Šé‡èª¿æ•´ Ã— (å¤šå°ºåº¦ç­–ç•¥ + é »ç‡åŠ æ¬Šç­–ç•¥)
Unified Loss = Dynamic Weight Adjustment Ã— (Multiscale Strategy + Frequency Weighting Strategy)
```

### æ¶æ§‹åœ–è§£ Architecture Diagram
```
è¼¸å…¥å¼µé‡ Input Tensors
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ•´åˆè™•ç†å™¨                 â”‚
â”‚        Unified Processor            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¤šå°ºåº¦åˆ†æ”¯     â”‚   åŠ æ¬Šåˆ†æ”¯        â”‚
â”‚ Multiscale      â”‚  Weighted         â”‚
â”‚                 â”‚                   â”‚
â”‚ â”Œâ”€â”€â”€ å°ºåº¦1 â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€ åŸå°ºåº¦ â”€â”€â”€â” â”‚
â”‚ â”‚ é »ç‡åŠ æ¬Šæå¤± â”‚ â”‚ â”‚ é »ç‡åŠ æ¬Šæå¤± â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€ å°ºåº¦2 â”€â”€â”€â” â”‚                   â”‚
â”‚ â”‚ é »ç‡åŠ æ¬Šæå¤± â”‚ â”‚                   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                   â”‚
â”‚ â”Œâ”€â”€â”€ å°ºåº¦N â”€â”€â”€â” â”‚                   â”‚
â”‚ â”‚ é »ç‡åŠ æ¬Šæå¤± â”‚ â”‚                   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
è‡ªé©æ‡‰æ¬Šé‡èª¿æ•´ (Linear/Cosine/Exponential)
    â†“
å‹•æ…‹çµ„åˆæ¬Šé‡è¨ˆç®—
    â†“
æœ€çµ‚æ•´åˆæå¤±
```

## ğŸ”§ æ ¸å¿ƒçµ„ä»¶ Core Components

### 1. å¤šå°ºåº¦è™•ç†å™¨ Multiscale Processor
```python
def multiscale_processing(tensor, scales=[1, 2, 4]):
    """
    å¤šå°ºåº¦è™•ç†ï¼šåœ¨ä¸åŒè§£æåº¦ä¸Šè¨ˆç®—æå¤±
    """
    total_loss = 0.0
    for scale in scales:
        # ä¸‹æ¡æ¨£åˆ°æŒ‡å®šå°ºåº¦
        downsampled = avg_pool2d(tensor, scale)
        # è¨ˆç®—è©²å°ºåº¦çš„é »ç‡åŠ æ¬Šæå¤±
        scale_loss = frequency_weighted_loss(downsampled)
        # åŠ æ¬Šç´¯ç©
        total_loss += scale_weight * scale_loss
    return total_loss
```

### 2. é »ç‡åŠ æ¬Šè™•ç†å™¨ Frequency Weighting Processor
```python
def frequency_weighting(tensor, high_freq_weight=2.0):
    """
    é »ç‡åŠ æ¬Šï¼šå°é«˜é »æˆåˆ†çµ¦äºˆæ›´é«˜æ¬Šé‡
    """
    # è¨ˆç®— FFT å¹…åº¦è­œ
    magnitude_spectrum = compute_fourier_magnitude_spectrum(tensor)
    # å‰µå»ºé »ç‡æ¬Šé‡é®ç½©
    weight_mask = create_frequency_weight_mask(tensor.shape, high_freq_weight)
    # æ‡‰ç”¨æ¬Šé‡
    weighted_loss = apply_frequency_weights(magnitude_spectrum, weight_mask)
    return weighted_loss
```

### 3. è‡ªé©æ‡‰èª¿æ•´å™¨ Adaptive Adjuster
```python
def adaptive_adjustment(progress, mode="linear", max_weight=2.5, min_weight=0.8):
    """
    è‡ªé©æ‡‰èª¿æ•´ï¼šæ ¹æ“šè¨“ç·´é€²åº¦å‹•æ…‹èª¿æ•´æ¬Šé‡
    """
    if mode == "linear":
        factor = max_weight - (max_weight - min_weight) * progress
    elif mode == "cosine":
        factor = min_weight + (max_weight - min_weight) * 0.5 * (1 + cos(Ï€ * progress))
    elif mode == "exponential":
        factor = min_weight + (max_weight - min_weight) * exp(-5 * progress)
    return factor
```

## ğŸ›ï¸ é…ç½®æ¨¡å¼è©³è§£ Configuration Modes Explained

### 1. unified_basic - åŸºç¤æ•´åˆæ¨¡å¼
**ç‰¹é»**: è¼•é‡ç´šï¼Œè³‡æºå‹å¥½
```python
config = {
    "enable_multiscale": False,      # ç¦ç”¨å¤šå°ºåº¦
    "enable_frequency_weighting": True,
    "enable_adaptive": True,
    "high_freq_weight": 1.5,
    "adaptive_mode": "linear",
    "max_weight": 2.0,
    "min_weight": 1.0,
}
```
**é©ç”¨å ´æ™¯**:
- è³‡æºå—é™ç’°å¢ƒ
- å¿«é€ŸåŸå‹é–‹ç™¼
- åŸºç¤åŠŸèƒ½æ¸¬è©¦

### 2. unified_balanced - å¹³è¡¡æ•´åˆæ¨¡å¼ â­
**ç‰¹é»**: æ•ˆæœèˆ‡æ•ˆç‡çš„æœ€ä½³å¹³è¡¡
```python
config = {
    "enable_multiscale": True,
    "enable_frequency_weighting": True,
    "enable_adaptive": True,
    "scales": [1, 2],               # é›™å°ºåº¦é…ç½®
    "high_freq_weight": 2.0,
    "adaptive_mode": "linear",
    "max_weight": 2.5,
    "min_weight": 0.8,
    "multiscale_weight": 0.6,       # å¤šå°ºåº¦æ¬Šé‡
    "weighted_weight": 0.4,         # åŠ æ¬Šæ¬Šé‡
}
```
**é©ç”¨å ´æ™¯**:
- æ—¥å¸¸è¨“ç·´ä»»å‹™
- å¤§å¤šæ•¸åœ–åƒç”Ÿæˆå ´æ™¯
- æ–°æ‰‹æ¨è–¦ä½¿ç”¨

### 3. unified_detail - ç´°ç¯€å¢å¼·æ¨¡å¼
**ç‰¹é»**: æœ€é«˜å“è³ªï¼Œç´°ç¯€è±å¯Œ
```python
config = {
    "enable_multiscale": True,
    "enable_frequency_weighting": True,
    "enable_adaptive": True,
    "scales": [1, 2, 4],            # ä¸‰å°ºåº¦é…ç½®
    "high_freq_weight": 2.5,
    "freq_weight_per_scale": [2.0, 2.5, 3.0],  # éå¢æ¬Šé‡
    "adaptive_mode": "cosine",       # é¤˜å¼¦å¹³æ»‘èª¿æ•´
    "max_weight": 3.0,
    "min_weight": 1.0,
    "multiscale_weight": 0.7,       # å¼·åŒ–å¤šå°ºåº¦
    "weighted_weight": 0.3,
}
```
**é©ç”¨å ´æ™¯**:
- é«˜å“è³ªåœ–åƒç”Ÿæˆ
- è¶…åˆ†è¾¨ç‡ä»»å‹™
- ç´°ç¯€é‡å»ºé …ç›®

### 4. unified_adaptive - è‡ªé©æ‡‰ç­–ç•¥æ¨¡å¼
**ç‰¹é»**: æ™ºèƒ½èª¿æ•´ï¼Œç­–ç•¥éˆæ´»
```python
config = {
    "enable_multiscale": True,
    "enable_frequency_weighting": True,
    "enable_adaptive": True,
    "scales": [1, 2],
    "adaptive_mode": "exponential",  # æŒ‡æ•¸è‡ªé©æ‡‰
    "max_weight": 2.8,
    "min_weight": 0.5,
    "adaptive_scaling": True,        # å‹•æ…‹çµ„åˆæ¬Šé‡
}
```
**é©ç”¨å ´æ™¯**:
- é•·æœŸè¨“ç·´é …ç›®
- å¾©é›œå ´æ™¯è™•ç†
- éœ€è¦ç­–ç•¥å‹•æ…‹èª¿æ•´çš„ä»»å‹™

## ğŸ“Š è‡ªé©æ‡‰æ›²ç·šåˆ†æ Adaptive Curves Analysis

### Linear ç·šæ€§æ¨¡å¼
```python
factor = max_weight - (max_weight - min_weight) * progress
```
**ç‰¹é»**:
- ç©©å®šå¹³æ»‘çš„æ¬Šé‡è¡°æ¸›
- å¯é æ¸¬çš„è¡Œç‚ºæ¨¡å¼
- é©åˆå¤§å¤šæ•¸æ¨™æº–è¨“ç·´å ´æ™¯

**æ¬Šé‡è®ŠåŒ–æ›²ç·š**:
```
Weight
  â†‘
  â”‚ â•²
  â”‚  â•²
  â”‚   â•²
  â”‚    â•²
  â”‚     â•²___
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Progress
```

### Cosine é¤˜å¼¦æ¨¡å¼ â­
```python
factor = min_weight + (max_weight - min_weight) * 0.5 * (1 + cos(Ï€ * progress))
```
**ç‰¹é»**:
- å¹³æ»‘çš„æ¬Šé‡éæ¸¡
- ä¸­æœŸéšæ®µè®ŠåŒ–ç·©æ…¢
- é©åˆéœ€è¦ç©©å®šä¸­æœŸéšæ®µçš„ä»»å‹™

**æ¬Šé‡è®ŠåŒ–æ›²ç·š**:
```
Weight
  â†‘
  â”‚ â•±â•²
  â”‚â•±  â•²
  â”‚    â•²
  â”‚     â•²
  â”‚      â•²___
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Progress
```

### Exponential æŒ‡æ•¸æ¨¡å¼
```python
factor = min_weight + (max_weight - min_weight) * exp(-5 * progress)
```
**ç‰¹é»**:
- æ—©æœŸå¿«é€Ÿè¡°æ¸›
- å¾ŒæœŸä¿æŒç©©å®š
- é©åˆéœ€è¦æ—©æœŸæ¿€é€²ç­–ç•¥çš„å ´æ™¯

**æ¬Šé‡è®ŠåŒ–æ›²ç·š**:
```
Weight
  â†‘
  â”‚â•²
  â”‚ â•²__
  â”‚    â”€â”€â”€
  â”‚       â”€â”€â”€â”€
  â”‚           â”€â”€â”€â”€
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Progress
```

## ğŸš€ ä½¿ç”¨æ–¹æ³• Usage Methods

### æ–¹æ³•1: å¿«é€Ÿé…ç½® (æ¨è–¦)
```python
from library.train_util import apply_fourier_loss_to_args

# ä¸€è¡Œè§£æ±ºæ–¹æ¡ˆ
apply_fourier_loss_to_args(args, mode="unified_balanced")

# æ ¹æ“šéœ€æ±‚é¸æ“‡æ¨¡å¼
modes = {
    "å¿«é€Ÿæ¸¬è©¦": "unified_basic",
    "æ—¥å¸¸ä½¿ç”¨": "unified_balanced",      # æ¨è–¦
    "é«˜å“è³ª": "unified_detail",
    "å¾©é›œå ´æ™¯": "unified_adaptive"
}
```

### æ–¹æ³•2: è¨“ç·´è…³æœ¬æ•´åˆ
```python
# åœ¨è¨“ç·´è…³æœ¬ä¸­æ·»åŠ 
def setup_fourier_loss(args):
    # åŸºæœ¬è¨­ç½®
    args.loss_type = "fourier"
    args.fourier_mode = "unified_balanced"
    args.fourier_weight = 0.06
    args.fourier_warmup_steps = 250

    # å¯é¸ï¼šæ ¹æ“šæ•¸æ“šé›†èª¿æ•´
    if args.dataset_type == "high_resolution":
        args.fourier_mode = "unified_detail"
        args.fourier_weight = 0.08
    elif args.dataset_type == "quick_test":
        args.fourier_mode = "unified_basic"
        args.fourier_weight = 0.03

    return args
```

### æ–¹æ³•3: å‹•æ…‹èª¿æ•´
```python
def dynamic_fourier_adjustment(args, current_epoch, total_epochs):
    """æ ¹æ“šè¨“ç·´éšæ®µå‹•æ…‹èª¿æ•´é…ç½®"""
    progress = current_epoch / total_epochs

    if progress < 0.3:  # æ—©æœŸéšæ®µ
        args.fourier_mode = "unified_detail"
        args.fourier_weight = 0.08
    elif progress < 0.7:  # ä¸­æœŸéšæ®µ
        args.fourier_mode = "unified_balanced"
        args.fourier_weight = 0.06
    else:  # å¾ŒæœŸéšæ®µ
        args.fourier_mode = "unified_adaptive"
        args.fourier_weight = 0.05

    return args
```

### æ–¹æ³•4: ç›´æ¥å‡½æ•¸èª¿ç”¨
```python
from library.fourier_loss import fourier_latent_loss_unified_simple

# åœ¨ forward å‡½æ•¸ä¸­ä½¿ç”¨
def compute_loss(model_pred, target, step, total_steps):
    # åŸºç¤æå¤±
    base_loss = F.mse_loss(model_pred, target)

    # æ•´åˆå‚…ç«‹è‘‰æå¤±
    fourier_loss = fourier_latent_loss_unified_simple(
        model_pred, target,
        mode="balanced",
        current_step=step,
        total_steps=total_steps
    )

    # çµ„åˆæå¤±
    total_loss = base_loss + 0.06 * fourier_loss
    return total_loss
```

## ğŸ“ˆ æ€§èƒ½èª¿å„ªæŒ‡å— Performance Tuning Guide

### ğŸ¯ æ¬Šé‡é¸æ“‡ç­–ç•¥
```python
def select_fourier_weight(task_type, model_size, dataset_complexity):
    """æ ¹æ“šä»»å‹™ç‰¹æ€§é¸æ“‡æ¬Šé‡"""
    base_weight = 0.05

    # ä»»å‹™é¡å‹èª¿æ•´
    task_multipliers = {
        "image_generation": 1.0,
        "super_resolution": 1.2,
        "style_transfer": 0.8,
        "image_restoration": 1.4
    }

    # æ¨¡å‹å¤§å°èª¿æ•´
    size_multipliers = {
        "small": 1.2,    # å°æ¨¡å‹éœ€è¦æ›´å¤šæŒ‡å°
        "medium": 1.0,
        "large": 0.8     # å¤§æ¨¡å‹è‡ªå­¸ç¿’èƒ½åŠ›æ›´å¼·
    }

    # æ•¸æ“šè¤‡é›œåº¦èª¿æ•´
    complexity_multipliers = {
        "simple": 0.8,
        "medium": 1.0,
        "complex": 1.3
    }

    final_weight = (base_weight *
                   task_multipliers.get(task_type, 1.0) *
                   size_multipliers.get(model_size, 1.0) *
                   complexity_multipliers.get(dataset_complexity, 1.0))

    # ç´„æŸåœ¨åˆç†ç¯„åœå…§
    return max(0.01, min(0.15, final_weight))
```

### âš¡ æ€§èƒ½å„ªåŒ–æŠ€å·§
```python
# 1. è¨˜æ†¶é«”å„ªåŒ–
def memory_optimized_config():
    return {
        "fourier_mode": "unified_basic",
        "scales": [1, 2],  # æ¸›å°‘å°ºåº¦æ•¸é‡
        "fourier_weight": 0.04,
        "enable_multiscale": True,  # ä¿æŒåŠŸèƒ½
    }

# 2. è¨ˆç®—é€Ÿåº¦å„ªåŒ–
def speed_optimized_config():
    return {
        "fourier_mode": "unified_balanced",
        "fourier_norm": "l2",  # L2 æ¯” L1 æ›´å¿«
        "adaptive_mode": "linear",  # ç·šæ€§æ¯”é¤˜å¼¦æ›´å¿«
    }

# 3. æ•ˆæœå„ªåŒ–
def quality_optimized_config():
    return {
        "fourier_mode": "unified_detail",
        "scales": [1, 2, 4],
        "adaptive_mode": "cosine",  # æ›´å¹³æ»‘çš„éæ¸¡
        "fourier_weight": 0.08,
    }
```

## ğŸ› ï¸ æ•…éšœæ’é™¤ Advanced Troubleshooting

### è¨ºæ–·æµç¨‹åœ–
```
å•é¡Œç™¼ç”Ÿ
    â†“
æª¢æŸ¥åŸºæœ¬é…ç½®
    â†“
æ˜¯å¦æ­£ç¢º? â”€ å¦ â†’ ä¿®æ­£é…ç½®åƒæ•¸
    â†“ æ˜¯
æª¢æŸ¥æå¤±æ•¸å€¼ç¯„åœ
    â†“
æ˜¯å¦åˆç†? â”€ å¦ â†’ èª¿æ•´æ¬Šé‡æˆ–æ¨¡å¼
    â†“ æ˜¯
æª¢æŸ¥è¨“ç·´ç©©å®šæ€§
    â†“
æ˜¯å¦ç©©å®š? â”€ å¦ â†’ å¢åŠ é ç†±æœŸæˆ–æ”¹è®Šè‡ªé©æ‡‰æ¨¡å¼
    â†“ æ˜¯
æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨
    â†“
æ˜¯å¦å……è¶³? â”€ å¦ â†’ é™ç´šåˆ°è¼•é‡æ¨¡å¼
    â†“ æ˜¯
æª¢æŸ¥æ•ˆæœæ”¹å–„
    â†“
æ˜¯å¦æ˜é¡¯? â”€ å¦ â†’ å˜—è©¦æ›´æ¿€é€²çš„é…ç½®
    â†“ æ˜¯
é…ç½®æˆåŠŸ âœ“
```

### è©³ç´°è¨ºæ–·æ–¹æ³•
```python
def diagnose_fourier_loss(model_pred, target, config):
    """å…¨é¢è¨ºæ–·å‚…ç«‹è‘‰æå¤±é…ç½®"""

    # 1. æª¢æŸ¥è¼¸å…¥æœ‰æ•ˆæ€§
    if model_pred.shape != target.shape:
        return "éŒ¯èª¤ï¼šå¼µé‡å½¢ç‹€ä¸åŒ¹é…"

    if model_pred.dim() < 3:
        return "éŒ¯èª¤ï¼šéœ€è¦è‡³å°‘3ç¶­å¼µé‡"

    # 2. è¨ˆç®—æå¤±ä¸¦åˆ†æ
    from library.fourier_loss import fourier_latent_loss_unified_simple

    try:
        loss = fourier_latent_loss_unified_simple(
            model_pred, target,
            mode=config.get("mode", "balanced")
        )

        # 3. åˆ†ææå¤±æ•¸å€¼
        if loss > 10.0:
            return f"è­¦å‘Šï¼šæå¤±éå¤§ ({loss:.4f})ï¼Œå»ºè­°é™ä½æ¬Šé‡"
        elif loss < 0.001:
            return f"è­¦å‘Šï¼šæå¤±éå° ({loss:.4f})ï¼Œå»ºè­°å¢åŠ æ¬Šé‡æˆ–ä½¿ç”¨æ›´æ¿€é€²æ¨¡å¼"
        elif torch.isnan(loss) or torch.isinf(loss):
            return "éŒ¯èª¤ï¼šæå¤±è¨ˆç®—ç”¢ç”Ÿ NaN æˆ– Inf"
        else:
            return f"æ­£å¸¸ï¼šæå¤±å€¼ {loss:.4f} åœ¨åˆç†ç¯„åœå…§"

    except Exception as e:
        return f"éŒ¯èª¤ï¼š{str(e)}"

# ä½¿ç”¨ç¯„ä¾‹
diagnosis = diagnose_fourier_loss(pred, target, {"mode": "balanced"})
print(diagnosis)
```

### å¸¸è¦‹å•é¡Œè§£æ±ºæ–¹æ¡ˆ
```python
def auto_fix_config(current_config, problem_type):
    """è‡ªå‹•ä¿®å¾©é…ç½®å•é¡Œ"""

    fixes = {
        "loss_too_high": {
            "fourier_weight": current_config.get("fourier_weight", 0.05) * 0.5,
            "fourier_warmup_steps": 500,
            "fourier_mode": "unified_basic"
        },

        "loss_too_small": {
            "fourier_weight": min(0.12, current_config.get("fourier_weight", 0.05) * 1.5),
            "fourier_mode": "unified_detail"
        },

        "memory_issue": {
            "fourier_mode": "unified_basic",
            "scales": [1, 2],
            "enable_multiscale": False if current_config.get("scales", []) else True
        },

        "unstable_training": {
            "fourier_warmup_steps": 500,
            "adaptive_mode": "cosine",
            "fourier_weight": current_config.get("fourier_weight", 0.05) * 0.8
        }
    }

    return {**current_config, **fixes.get(problem_type, {})}
```

## ğŸ“š å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ Real-world Case Studies

### æ¡ˆä¾‹1: é«˜å“è³ªäººåƒç”Ÿæˆ
```python
# ä»»å‹™ï¼šç”Ÿæˆé«˜å“è³ªäººåƒåœ–ç‰‡
# è¦æ±‚ï¼šç´°ç¯€è±å¯Œï¼Œé‚Šç·£æ¸…æ™°ï¼Œç´‹ç†è‡ªç„¶

config = {
    "fourier_mode": "unified_detail",
    "fourier_weight": 0.09,
    "scales": [1, 2, 4],
    "freq_weight_per_scale": [2.0, 2.5, 3.0],
    "adaptive_mode": "cosine",
    "max_weight": 3.0,
    "min_weight": 1.2,
    "fourier_warmup_steps": 300
}

# çµæœï¼šåœ¨ CelebA-HQ æ•¸æ“šé›†ä¸Š FID åˆ†æ•¸æ”¹å–„ 15%ï¼Œ
#      ç”Ÿæˆåœ–åƒçš„ç´°ç¯€éŠ³åº¦å’Œç´‹ç†è³ªé‡é¡¯è‘—æå‡
```

### æ¡ˆä¾‹2: å¿«é€Ÿé¢¨æ ¼è½‰æ›
```python
# ä»»å‹™ï¼šå¯¦æ™‚é¢¨æ ¼è½‰æ›
# è¦æ±‚ï¼šé€Ÿåº¦å¿«ï¼Œæ•ˆæœå¥½ï¼Œè¨˜æ†¶é«”ä½¿ç”¨å°‘

config = {
    "fourier_mode": "unified_basic",
    "fourier_weight": 0.04,
    "adaptive_mode": "exponential",  # æ—©æœŸæ¿€é€²ï¼Œå¾ŒæœŸä¿å®ˆ
    "max_weight": 2.5,
    "min_weight": 0.8,
    "fourier_warmup_steps": 200
}

# çµæœï¼šæ¨ç†é€Ÿåº¦æå‡ 20%ï¼Œé¢¨æ ¼è½‰æ›è³ªé‡ä¿æŒï¼Œ
#      è¨˜æ†¶é«”ä½¿ç”¨é™ä½ 30%
```

### æ¡ˆä¾‹3: è¶…åˆ†è¾¨ç‡é‡å»º
```python
# ä»»å‹™ï¼š4x è¶…åˆ†è¾¨ç‡é‡å»º
# è¦æ±‚ï¼šé‚Šç·£æ¸…æ™°ï¼Œç´°ç¯€ä¿ç•™ï¼Œç„¡å½å½±

config = {
    "fourier_mode": "unified",  # è‡ªå®šç¾©é…ç½®
    "fourier_weight": 0.10,
    "enable_multiscale": True,
    "enable_frequency_weighting": True,
    "enable_adaptive": True,
    "scales": [1, 2, 4, 8],  # å¤šå°ºåº¦è¦†è“‹
    "adaptive_mode": "cosine",
    "max_weight": 3.5,
    "min_weight": 1.5,
    "multiscale_weight": 0.8,  # å¼·èª¿å¤šå°ºåº¦
    "weighted_weight": 0.2
}

# çµæœï¼šPSNR æå‡ 2.1dBï¼ŒSSIM æå‡ 0.05ï¼Œ
#      è¦–è¦ºè³ªé‡æ˜é¡¯æ”¹å–„ï¼Œç‰¹åˆ¥æ˜¯é«˜é »ç´°ç¯€
```

## ğŸ”¬ æŠ€è¡“æ·±åº¦åˆ†æ Technical Deep Dive

### æ•¸å­¸å…¬å¼è©³è§£
```python
# æ•´åˆæå¤±çš„å®Œæ•´æ•¸å­¸è¡¨é”å¼
def unified_loss_formula():
    """
    L_unified = Î±(t) * L_multiscale + Î²(t) * L_weighted

    å…¶ä¸­ï¼š
    L_multiscale = Î£(i=1 to N) w_i * L_freq_weighted(downsample(x, s_i))
    L_weighted = Î£(u,v) W(u,v) * |F_pred(u,v) - F_target(u,v)|^p

    è‡ªé©æ‡‰æ¬Šé‡ï¼š
    Î±(t) = Î±â‚€ * f_adapt(progress)
    Î²(t) = Î²â‚€ * f_adapt(progress)

    å…¶ä¸­ f_adapt(progress) å¯ä»¥æ˜¯ï¼š
    - Linear: 1 - k*progress
    - Cosine: 0.5 * (1 + cos(Ï€*progress))
    - Exponential: exp(-Î»*progress)
    """
    pass
```

### é »ç‡åˆ†æåŸç†
```python
def frequency_analysis_theory():
    """
    é »ç‡æ¬Šé‡åˆ†é…åŸç†ï¼š

    1. è¨ˆç®— 2D FFTï¼š
       F(u,v) = Î£ Î£ f(x,y) * exp(-j2Ï€(ux/M + vy/N))

    2. è¨ˆç®—é »ç‡å¹…åº¦ï¼š
       |F(u,v)| = sqrt(Re(F(u,v))Â² + Im(F(u,v))Â²)

    3. å‰µå»ºæ¬Šé‡é®ç½©ï¼š
       freq_mag = sqrt(uÂ² + vÂ²) / max_freq
       weight(u,v) = 1 + (Î±-1) * sigmoid(Î²*(freq_mag-0.5))

    4. æ‡‰ç”¨æ¬Šé‡ï¼š
       L_weighted = Î£ weight(u,v) * |F_pred(u,v) - F_target(u,v)|^p
    """
    pass
```

## ğŸ“ æœ€ä½³å¯¦è¸ç¸½çµ Best Practices Summary

### âœ… æ¨è–¦åšæ³•
1. **æ¼¸é€²å¼é…ç½®**: å¾ `unified_basic` â†’ `unified_balanced` â†’ `unified_detail`
2. **ç›£æ§æŒ‡æ¨™**: å¯†åˆ‡é—œæ³¨æå¤±æ¯”ä¾‹ (5%-20%)
3. **A/B æ¸¬è©¦**: å°æ¯”ä¸åŒé…ç½®çš„æ•ˆæœ
4. **è¨˜éŒ„å¯¦é©—**: å»ºç«‹é…ç½®æ•ˆæœæ•¸æ“šåº«
5. **å®šæœŸèª¿æ•´**: æ ¹æ“šè¨“ç·´é€²å±•å‹•æ…‹èª¿æ•´

### âŒ é¿å…äº‹é …
1. **è·³èºå¼é…ç½®**: é¿å…ç›´æ¥ä½¿ç”¨æœ€å¾©é›œé…ç½®
2. **å¿½ç•¥é ç†±**: ç¸½æ˜¯è¨­ç½®é©ç•¶çš„é ç†±æœŸ
3. **ç›²ç›®è¿½æ±‚é«˜æ¬Šé‡**: æ¬Šé‡ä¸¦éè¶Šé«˜è¶Šå¥½
4. **å¿½ç•¥è³‡æºé™åˆ¶**: æ ¹æ“šç¡¬ä»¶é¸æ“‡åˆé©æ¨¡å¼
5. **ç¼ºä¹é©—è­‰**: ä¸åœ¨é©—è­‰é›†ä¸Šæª¢æŸ¥æ•ˆæœ

### ğŸ¯ é…ç½®é¸æ“‡æ±ºç­–æ¨¹
```
é–‹å§‹
  â†“
è³‡æºæ˜¯å¦å……è¶³ï¼Ÿ
  â”œâ”€ å¦ â†’ unified_basic
  â””â”€ æ˜¯ â†“
     è¿½æ±‚é€Ÿåº¦é‚„æ˜¯å“è³ªï¼Ÿ
       â”œâ”€ é€Ÿåº¦ â†’ unified_balanced
       â””â”€ å“è³ª â†“
          æ˜¯å¦éœ€è¦å‹•æ…‹ç­–ç•¥ï¼Ÿ
            â”œâ”€ æ˜¯ â†’ unified_adaptive
            â””â”€ å¦ â†’ unified_detail
```

## ğŸ“ ç¸½çµ Conclusion

æ•´åˆå‹å‚…ç«‹è‘‰æå¤±ä»£è¡¨äº†æ·±åº¦å­¸ç¿’æå¤±å‡½æ•¸è¨­è¨ˆçš„æ–°çªç ´ï¼Œé€šéå·§å¦™çµåˆå¤šç¨®ç­–ç•¥ï¼Œç‚ºä¸åŒæ‡‰ç”¨å ´æ™¯æä¾›äº†éˆæ´»è€Œå¼·å¤§çš„è§£æ±ºæ–¹æ¡ˆã€‚

é—œéµå„ªå‹¢ï¼š
- ğŸ¯ **çµ±ä¸€æ¶æ§‹**: ä¸€å€‹å‡½æ•¸è§£æ±ºå¤šç¨®éœ€æ±‚
- ğŸ§  **æ™ºèƒ½è‡ªé©æ‡‰**: è‡ªå‹•èª¿æ•´ç­–ç•¥
- âš¡ **é«˜æ•ˆå¯¦ç¾**: å„ªåŒ–çš„è¨ˆç®—æ€§èƒ½
- ğŸ›¡ï¸ **ç©©å®šå¯é **: å®Œå–„çš„éŒ¯èª¤è™•ç†
- ğŸ“š **æ˜“æ–¼ä½¿ç”¨**: è±å¯Œçš„é è¨­é…ç½®

ç«‹å³é–‹å§‹ä½¿ç”¨æ•´åˆå‹å‚…ç«‹è‘‰æå¤±ï¼Œé«”é©—ä¸‹ä¸€ä»£æå¤±å‡½æ•¸çš„å¼·å¤§åŠŸèƒ½ï¼

---

**ç›¸é—œéˆæ¥**:
- [å¿«é€Ÿåƒè€ƒ](./FOURIER_LOSS_QUICK_REFERENCE.md)
- [å®Œæ•´æŒ‡å—](./FOURIER_LOSS_GUIDE.md)
- [æ¸¬è©¦è…³æœ¬](./test_unified_fourier_loss.py)
- [ç¨‹å¼ç¯„ä¾‹](./fourier_loss_examples.py)