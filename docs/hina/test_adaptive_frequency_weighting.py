#!/usr/bin/env python3
"""
è‡ªé©æ‡‰é »ç‡æ¬Šé‡åŠŸèƒ½æ¸¬è©¦è…³æœ¬

æ¸¬è©¦ HinaAdaptive å„ªåŒ–å™¨çš„ adaptive_frequency_weighting åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ åº«è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

from library.hina_adaptive import HinaAdaptive


class SimpleTestModel(nn.Module):
    """ç°¡å–®çš„æ¸¬è©¦æ¨¡å‹"""
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.fc = nn.Linear(32 * 32 * 32, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = x.view(x.size(0), -1)
        return self.fc(x)


def test_adaptive_frequency_weighting():
    """æ¸¬è©¦è‡ªé©æ‡‰é »ç‡æ¬Šé‡åŠŸèƒ½"""
    print("=== è‡ªé©æ‡‰é »ç‡æ¬Šé‡åŠŸèƒ½æ¸¬è©¦ ===")

    # å‰µå»ºæ¨¡å‹å’Œæ•¸æ“š
    model = SimpleTestModel()
    input_data = torch.randn(2, 3, 32, 32)
    target = torch.randint(0, 10, (2,))

    # æ¸¬è©¦1ï¼šå•Ÿç”¨è‡ªé©æ‡‰é »ç‡æ¬Šé‡
    print("\n1. æ¸¬è©¦å•Ÿç”¨è‡ªé©æ‡‰é »ç‡æ¬Šé‡çš„å„ªåŒ–å™¨")
    optimizer_adaptive = HinaAdaptive(
        model.parameters(),
        lr=0.001,
        fourier_feature_loss=True,
        super_resolution_mode=True,
        adaptive_frequency_weighting=True,  # å•Ÿç”¨
        fourier_high_freq_preservation=0.3,
        fourier_detail_enhancement=0.2,
        super_resolution_scale=4
    )

    print(f"å„ªåŒ–å™¨å‰µå»ºæˆåŠŸï¼Œadaptive_frequency_weighting = {optimizer_adaptive.adaptive_frequency_weighting}")

    # ç²å–å„ªåŒ–å™¨ä¿¡æ¯
    info = optimizer_adaptive.get_optimization_info()
    print(f"å‚…ç«‹è‘‰ç‰¹å¾µæå¤±å·²å•Ÿç”¨ï¼š{info['features']['fourier_feature_loss']}")
    print(f"è‡ªé©æ‡‰é »ç‡æ¬Šé‡å·²å•Ÿç”¨ï¼š{info['features']['adaptive_frequency_weighting']}")

    # åŸ·è¡Œå¹¾æ­¥è¨“ç·´
    criterion = nn.CrossEntropyLoss()

    for step in range(3):
        optimizer_adaptive.zero_grad()
        output = model(input_data)
        loss = criterion(output, target)
        loss.backward()

        print(f"\næ­¥é©Ÿ {step + 1}:")
        print(f"  æå¤±: {loss.item():.4f}")

        # æª¢æŸ¥æ˜¯å¦æœ‰è‡ªé©æ‡‰æ¬Šé‡ç‹€æ…‹
        param_groups_metadata = optimizer_adaptive.param_groups_metadata
        for group_idx, group_meta in param_groups_metadata.items():
            for param_id, compact_state in group_meta['compact_states'].items():
                if compact_state.get_scalar('adaptive_low_freq_weight', None) is not None:
                    low_weight = compact_state.get_scalar('adaptive_low_freq_weight', 1.0)
                    mid_weight = compact_state.get_scalar('adaptive_mid_freq_weight', 1.0)
                    high_weight = compact_state.get_scalar('adaptive_high_freq_weight', 1.0)
                    print(f"  è‡ªé©æ‡‰æ¬Šé‡ - ä½é »: {low_weight:.3f}, ä¸­é »: {mid_weight:.3f}, é«˜é »: {high_weight:.3f}")
                    break
            break

        optimizer_adaptive.step()

    # æ¸¬è©¦2ï¼šç¦ç”¨è‡ªé©æ‡‰é »ç‡æ¬Šé‡é€²è¡Œæ¯”è¼ƒ
    print("\n2. æ¸¬è©¦ç¦ç”¨è‡ªé©æ‡‰é »ç‡æ¬Šé‡çš„å„ªåŒ–å™¨")
    model2 = SimpleTestModel()
    optimizer_fixed = HinaAdaptive(
        model2.parameters(),
        lr=0.001,
        fourier_feature_loss=True,
        super_resolution_mode=True,
        adaptive_frequency_weighting=False,  # ç¦ç”¨
        fourier_high_freq_preservation=0.3,
        fourier_detail_enhancement=0.2,
        super_resolution_scale=4
    )

    print(f"å„ªåŒ–å™¨å‰µå»ºæˆåŠŸï¼Œadaptive_frequency_weighting = {optimizer_fixed.adaptive_frequency_weighting}")

    # åŸ·è¡Œä¸€æ­¥è¨“ç·´é€²è¡Œæ¯”è¼ƒ
    optimizer_fixed.zero_grad()
    output2 = model2(input_data)
    loss2 = criterion(output2, target)
    loss2.backward()

    print(f"æå¤±: {loss2.item():.4f}")

    # æª¢æŸ¥æ˜¯å¦æ²’æœ‰è‡ªé©æ‡‰æ¬Šé‡ç‹€æ…‹
    param_groups_metadata2 = optimizer_fixed.param_groups_metadata
    has_adaptive_weights = False
    for group_idx, group_meta in param_groups_metadata2.items():
        for param_id, compact_state in group_meta['compact_states'].items():
            if compact_state.get_scalar('adaptive_low_freq_weight', None) is not None:
                has_adaptive_weights = True
                break
        break

    print(f"æ˜¯å¦åŒ…å«è‡ªé©æ‡‰æ¬Šé‡ç‹€æ…‹: {has_adaptive_weights}")

    optimizer_fixed.step()

    print("\n=== æ¸¬è©¦å®Œæˆ ===")
    print("âœ… adaptive_frequency_weighting åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
    return True


def test_frequency_weight_adaptation():
    """æ¸¬è©¦é »ç‡æ¬Šé‡è‡ªé©æ‡‰éç¨‹"""
    print("\n=== é »ç‡æ¬Šé‡è‡ªé©æ‡‰éç¨‹æ¸¬è©¦ ===")

    # å‰µå»ºä¸€å€‹ç°¡å–®çš„2Dåƒæ•¸ç”¨æ–¼æ¸¬è©¦
    param = nn.Parameter(torch.randn(64, 64))
    optimizer = HinaAdaptive(
        [param],
        lr=0.001,
        fourier_feature_loss=True,
        super_resolution_mode=True,
        adaptive_frequency_weighting=True,
        super_resolution_scale=4
    )

    # æ¨¡æ“¬ä¸åŒçš„æ¢¯åº¦æ¨¡å¼ä¾†æ¸¬è©¦æ¬Šé‡è‡ªé©æ‡‰
    patterns = [
        ("ä½é »ä¸»å°", torch.ones(64, 64) * 0.1),  # ä½é »æ¨¡å¼
        ("é«˜é »ä¸»å°", torch.randn(64, 64) * 0.1),  # é«˜é »å™ªè²æ¨¡å¼
        ("æ··åˆæ¨¡å¼", torch.sin(torch.linspace(0, 10*3.14159, 64*64)).reshape(64, 64) * 0.1)  # ä¸­é »æ¨¡å¼
    ]

    for pattern_name, grad_pattern in patterns:
        print(f"\næ¸¬è©¦ {pattern_name}:")

        # åŸ·è¡Œ5æ­¥ä¾†è§€å¯Ÿæ¬Šé‡è®ŠåŒ–
        initial_weights = None
        for step in range(5):
            optimizer.zero_grad()
            param.grad = grad_pattern + torch.randn_like(grad_pattern) * 0.01

            # ç²å–ç•¶å‰æ¬Šé‡
            param_groups_metadata = optimizer.param_groups_metadata
            for group_idx, group_meta in param_groups_metadata.items():
                for param_id, compact_state in group_meta['compact_states'].items():
                    if param_id == id(param):
                        low_weight = compact_state.get_scalar('adaptive_low_freq_weight', 1.0)
                        mid_weight = compact_state.get_scalar('adaptive_mid_freq_weight', 1.0)
                        high_weight = compact_state.get_scalar('adaptive_high_freq_weight', 1.0)

                        if initial_weights is None:
                            initial_weights = (low_weight, mid_weight, high_weight)

                        print(f"  æ­¥é©Ÿ {step + 1}: ä½é »={low_weight:.3f}, ä¸­é »={mid_weight:.3f}, é«˜é »={high_weight:.3f}")
                        break
                break

            optimizer.step()

        # é¡¯ç¤ºæ¬Šé‡è®ŠåŒ–
        final_weights = (low_weight, mid_weight, high_weight)
        print(f"  æ¬Šé‡è®ŠåŒ–: ä½é » {initial_weights[0]:.3f}â†’{final_weights[0]:.3f}, "
              f"ä¸­é » {initial_weights[1]:.3f}â†’{final_weights[1]:.3f}, "
              f"é«˜é » {initial_weights[2]:.3f}â†’{final_weights[2]:.3f}")

    print("\nâœ… é »ç‡æ¬Šé‡è‡ªé©æ‡‰éç¨‹æ¸¬è©¦å®Œæˆï¼")


if __name__ == "__main__":
    try:
        # æ¸¬è©¦åŸºæœ¬åŠŸèƒ½
        test_adaptive_frequency_weighting()

        # æ¸¬è©¦è‡ªé©æ‡‰éç¨‹
        test_frequency_weight_adaptation()

        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼adaptive_frequency_weighting åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")

    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()