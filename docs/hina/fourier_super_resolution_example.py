#!/usr/bin/env python3
"""
å‚…ç«‹è‘‰ç‰¹å¾µæå¤±è¶…è§£æåº¦å„ªåŒ–ç¯„ä¾‹è…³æœ¬

æœ¬è…³æœ¬å±•ç¤ºå¦‚ä½•ä½¿ç”¨ HinaAdaptive å„ªåŒ–å™¨çš„å‚…ç«‹è‘‰ç‰¹å¾µæå¤±åŠŸèƒ½
ä¾†å„ªåŒ–è¶…è§£æåº¦æ¨¡å‹çš„è¨“ç·´ï¼Œç‰¹åˆ¥é‡å°ç´°ç¯€ä¿æŒå’Œæ¨¡ç³ŠæŠ‘åˆ¶ã€‚

ä½œè€…: Hina
æ—¥æœŸ: 2024
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, Tuple, Optional
import sys
import os

# æ·»åŠ åº«è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from library.hina_adaptive import HinaAdaptive

class SuperResolutionModel(nn.Module):
    """
    ç°¡å–®çš„è¶…è§£æåº¦æ¨¡å‹ç¤ºä¾‹
    """
    def __init__(self, scale_factor: int = 4, num_channels: int = 3):
        super().__init__()
        self.scale_factor = scale_factor

        # ç‰¹å¾µæå–å±¤
        self.feature_extraction = nn.Sequential(
            nn.Conv2d(num_channels, 64, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.ReLU(inplace=True),
        )

        # æ®˜å·®å¡Š
        self.residual_blocks = nn.Sequential(*[
            ResidualBlock(64) for _ in range(6)
        ])

        # ä¸Šæ¡æ¨£å±¤
        self.upsampling = nn.Sequential(
            nn.Conv2d(64, 64 * (scale_factor ** 2), 3, padding=1),
            nn.PixelShuffle(scale_factor),
            nn.Conv2d(64, num_channels, 3, padding=1),
            nn.Tanh()
        )

    def forward(self, x):
        features = self.feature_extraction(x)
        residual = self.residual_blocks(features)
        output = self.upsampling(features + residual)
        return output

class ResidualBlock(nn.Module):
    """æ®˜å·®å¡Š"""
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        residual = x
        out = self.relu(self.conv1(x))
        out = self.conv2(out)
        return out + residual

def create_synthetic_data(batch_size: int = 8, lr_size: int = 32, scale: int = 4) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    å‰µå»ºåˆæˆçš„è¶…è§£æåº¦è¨“ç·´æ•¸æ“š

    Args:
        batch_size: æ‰¹æ¬¡å¤§å°
        lr_size: ä½è§£æåº¦åœ–åƒå¤§å°
        scale: æ”¾å¤§å€æ•¸

    Returns:
        ä½è§£æåº¦å’Œé«˜è§£æåº¦åœ–åƒå°
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # å‰µå»ºé«˜è§£æåº¦åœ–åƒï¼ˆå«æœ‰è±å¯Œç´°ç¯€ï¼‰
    hr_size = lr_size * scale
    hr_images = torch.randn(batch_size, 3, hr_size, hr_size, device=device)

    # æ·»åŠ ä¸€äº›ç´‹ç†å’Œé‚Šç·£
    for i in range(batch_size):
        # æ·»åŠ ç¶²æ ¼ç´‹ç†
        x = torch.arange(hr_size, device=device, dtype=torch.float32)
        y = torch.arange(hr_size, device=device, dtype=torch.float32)
        xx, yy = torch.meshgrid(x, y, indexing='ij')

        # å‰µå»ºä¸åŒé »ç‡çš„æ­£å¼¦æ³¢ç´‹ç†
        texture = (torch.sin(xx * 0.2) * torch.cos(yy * 0.15) +
                  torch.sin(xx * 0.5) * torch.cos(yy * 0.3) * 0.5)

        hr_images[i] += texture.unsqueeze(0) * 0.3

    # å‰µå»ºä½è§£æåº¦åœ–åƒï¼ˆä¸‹æ¡æ¨£ï¼‰
    lr_images = F.interpolate(hr_images, size=(lr_size, lr_size), mode='bicubic', align_corners=False)

    # æ­£è¦åŒ–åˆ° [-1, 1]
    hr_images = torch.tanh(hr_images)
    lr_images = torch.tanh(lr_images)

    return lr_images, hr_images

def compute_image_metrics(pred: torch.Tensor, target: torch.Tensor) -> Dict[str, float]:
    """
    è¨ˆç®—åœ–åƒå“è³ªæŒ‡æ¨™

    Args:
        pred: é æ¸¬åœ–åƒ
        target: ç›®æ¨™åœ–åƒ

    Returns:
        åŒ…å«å„ç¨®æŒ‡æ¨™çš„å­—å…¸
    """
    with torch.no_grad():
        # PSNR
        mse = F.mse_loss(pred, target)
        psnr = 20 * torch.log10(2.0 / torch.sqrt(mse))

        # é«˜é »èƒ½é‡æ¯”è¼ƒ
        pred_fft = torch.fft.fft2(pred)
        target_fft = torch.fft.fft2(target)

        pred_magnitude = torch.abs(pred_fft)
        target_magnitude = torch.abs(target_fft)

        # è¨ˆç®—é«˜é »èƒ½é‡
        h, w = pred.shape[-2:]
        freq_y = torch.fft.fftfreq(h, device=pred.device).unsqueeze(1)
        freq_x = torch.fft.fftfreq(w, device=pred.device).unsqueeze(0)
        freq_radius = torch.sqrt(freq_y**2 + freq_x**2)

        high_freq_mask = freq_radius > 0.3
        pred_hf_energy = torch.sum(pred_magnitude * high_freq_mask.float())
        target_hf_energy = torch.sum(target_magnitude * high_freq_mask.float())

        hf_preservation = pred_hf_energy / (target_hf_energy + 1e-8)

        return {
            'psnr': psnr.item(),
            'mse': mse.item(),
            'high_freq_preservation': hf_preservation.item()
        }

def train_with_fourier_loss(scale_factor: int = 4):
    """
    ä½¿ç”¨å‚…ç«‹è‘‰ç‰¹å¾µæå¤±è¨“ç·´è¶…è§£æåº¦æ¨¡å‹

    Args:
        scale_factor: è¶…è§£æåº¦æ”¾å¤§å€æ•¸
    """
    print(f"ğŸš€ é–‹å§‹ä½¿ç”¨å‚…ç«‹è‘‰ç‰¹å¾µæå¤±è¨“ç·´ {scale_factor}x è¶…è§£æåº¦æ¨¡å‹")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    # å‰µå»ºæ¨¡å‹
    model = SuperResolutionModel(scale_factor=scale_factor).to(device)
    print(f"æ¨¡å‹åƒæ•¸é‡: {sum(p.numel() for p in model.parameters()):,}")

    # å‰µå»ºå‚…ç«‹è‘‰ç‰¹å¾µæå¤±å„ªåŒ–å™¨
    optimizer = HinaAdaptive(
        model.parameters(),
        lr=1e-4,
        # å•Ÿç”¨å‚…ç«‹è‘‰ç‰¹å¾µæå¤±
        fourier_feature_loss=True,
        super_resolution_mode=True,
        super_resolution_scale=scale_factor,
        # å‚…ç«‹è‘‰ç‰¹å¾µåƒæ•¸èª¿æ•´
        fourier_high_freq_preservation=0.3,     # é«˜é »ç´°ç¯€ä¿æŒ
        fourier_detail_enhancement=0.25,        # ç´°ç¯€å¢å¼·
        fourier_blur_suppression=0.2,           # æ¨¡ç³ŠæŠ‘åˆ¶
        texture_coherence_penalty=0.1,          # ç´‹ç†ä¸€è‡´æ€§
        adaptive_frequency_weighting=True,      # è‡ªé©æ‡‰é »ç‡æ¬Šé‡
        frequency_domain_lr_scaling=True,       # é »åŸŸå­¸ç¿’ç‡ç¸®æ”¾
        # è¨˜æ†¶é«”å„ªåŒ–
        memory_efficient=True,
        vram_budget_gb=8.0,
        reduce_precision=True,
        # å…¶ä»–åŠŸèƒ½
        use_dynamic_adaptation=True,
        edge_suppression=True,
        spatial_awareness=True
    )

    print("âœ… HinaAdaptive å„ªåŒ–å™¨é…ç½®:")
    optimizer_info = optimizer.get_optimization_info()
    for key, value in optimizer_info['fourier_super_resolution_config'].items():
        print(f"   {key}: {value}")

    print("\nğŸ”§ è¨“ç·´é…ç½®:")
    print(f"   æ”¾å¤§å€æ•¸: {scale_factor}x")
    print(f"   å­¸ç¿’ç‡: {optimizer.defaults['lr']}")
    print(f"   è¨˜æ†¶é«”é ç®—: {optimizer.vram_budget_gb}GB")

    # è¨“ç·´å¾ªç’°
    model.train()
    training_history = {
        'losses': [],
        'psnr': [],
        'high_freq_preservation': []
    }

    print("\nğŸ¯ é–‹å§‹è¨“ç·´...")
    print("-" * 60)

    for epoch in range(20):
        epoch_losses = []
        epoch_metrics = {'psnr': [], 'high_freq_preservation': []}

        for step in range(10):  # æ¯å€‹ epoch 10 å€‹æ­¥é©Ÿ
            # ç”Ÿæˆè¨“ç·´æ•¸æ“š
            lr_images, hr_images = create_synthetic_data(batch_size=4, lr_size=32, scale=scale_factor)

            # å‰å‘å‚³æ’­
            sr_images = model(lr_images)

            # è¨ˆç®—æå¤±
            loss = F.mse_loss(sr_images, hr_images)

            # åå‘å‚³æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # è¨˜éŒ„æŒ‡æ¨™
            epoch_losses.append(loss.item())

            if step % 5 == 0:  # æ¯ 5 æ­¥è¨ˆç®—ä¸€æ¬¡è©³ç´°æŒ‡æ¨™
                metrics = compute_image_metrics(sr_images, hr_images)
                epoch_metrics['psnr'].append(metrics['psnr'])
                epoch_metrics['high_freq_preservation'].append(metrics['high_freq_preservation'])

        # çµ±è¨ˆæœ¬ epoch çµæœ
        avg_loss = np.mean(epoch_losses)
        avg_psnr = np.mean(epoch_metrics['psnr']) if epoch_metrics['psnr'] else 0
        avg_hf_preservation = np.mean(epoch_metrics['high_freq_preservation']) if epoch_metrics['high_freq_preservation'] else 0

        training_history['losses'].append(avg_loss)
        training_history['psnr'].append(avg_psnr)
        training_history['high_freq_preservation'].append(avg_hf_preservation)

        # é¡¯ç¤ºé€²åº¦
        print(f"Epoch {epoch+1:2d}/20 | "
              f"Loss: {avg_loss:.6f} | "
              f"PSNR: {avg_psnr:.2f}dB | "
              f"HFä¿æŒ: {avg_hf_preservation:.3f}")

        # æ¯ 5 å€‹ epoch é¡¯ç¤ºè¨˜æ†¶é«”ç‹€æ…‹
        if (epoch + 1) % 5 == 0:
            memory_stats = optimizer.get_memory_stats()
            print(f"   ğŸ’¾ è¨˜æ†¶é«”å£“åŠ›: {memory_stats['memory_pressure']:.1%}")

    print("\nâœ… è¨“ç·´å®Œæˆï¼")

    # é¡¯ç¤ºæœ€çµ‚çµæœ
    final_loss = training_history['losses'][-1]
    final_psnr = training_history['psnr'][-1]
    final_hf_preservation = training_history['high_freq_preservation'][-1]

    print(f"\nğŸ“Š æœ€çµ‚çµæœ:")
    print(f"   æœ€çµ‚æå¤±: {final_loss:.6f}")
    print(f"   æœ€çµ‚ PSNR: {final_psnr:.2f}dB")
    print(f"   é«˜é »ä¿æŒç‡: {final_hf_preservation:.3f}")

    # æ”¹å–„åˆ†æ
    initial_loss = training_history['losses'][0]
    initial_psnr = training_history['psnr'][0] if training_history['psnr'][0] > 0 else 20

    loss_improvement = (initial_loss - final_loss) / initial_loss * 100
    psnr_improvement = final_psnr - initial_psnr

    print(f"\nğŸ¯ æ”¹å–„å¹…åº¦:")
    print(f"   æå¤±é™ä½: {loss_improvement:.1f}%")
    print(f"   PSNR æå‡: {psnr_improvement:.2f}dB")

    return training_history, optimizer

def compare_with_baseline(scale_factor: int = 4):
    """
    èˆ‡åŸºæº–å„ªåŒ–å™¨é€²è¡Œæ¯”è¼ƒ

    Args:
        scale_factor: è¶…è§£æåº¦æ”¾å¤§å€æ•¸
    """
    print(f"\nğŸ”¬ èˆ‡åŸºæº–å„ªåŒ–å™¨æ¯”è¼ƒ ({scale_factor}x è¶…è§£æåº¦)")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    results = {}

    for optimizer_type in ['baseline_adam', 'hina_adaptive_fourier']:
        print(f"\nè¨“ç·´ä½¿ç”¨: {optimizer_type}")

        # å‰µå»ºæ–°æ¨¡å‹
        model = SuperResolutionModel(scale_factor=scale_factor).to(device)

        if optimizer_type == 'baseline_adam':
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        else:
            optimizer = HinaAdaptive(
                model.parameters(),
                lr=1e-4,
                fourier_feature_loss=True,
                super_resolution_mode=True,
                super_resolution_scale=scale_factor,
                fourier_high_freq_preservation=0.3,
                fourier_detail_enhancement=0.25,
                fourier_blur_suppression=0.2,
                memory_efficient=True
            )

        # è¨“ç·´
        model.train()
        final_metrics = {'loss': 0, 'psnr': 0, 'hf_preservation': 0}

        for epoch in range(10):  # è¼ƒçŸ­çš„æ¯”è¼ƒè¨“ç·´
            for step in range(5):
                lr_images, hr_images = create_synthetic_data(batch_size=4, lr_size=32, scale=scale_factor)

                sr_images = model(lr_images)
                loss = F.mse_loss(sr_images, hr_images)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                if epoch == 9 and step == 4:  # æœ€å¾Œä¸€æ­¥
                    metrics = compute_image_metrics(sr_images, hr_images)
                    final_metrics['loss'] = loss.item()
                    final_metrics['psnr'] = metrics['psnr']
                    final_metrics['hf_preservation'] = metrics['high_freq_preservation']

        results[optimizer_type] = final_metrics
        print(f"   æœ€çµ‚ PSNR: {final_metrics['psnr']:.2f}dB")
        print(f"   é«˜é »ä¿æŒ: {final_metrics['hf_preservation']:.3f}")

    # æ¯”è¼ƒçµæœ
    print(f"\nğŸ“ˆ æ¯”è¼ƒçµæœ:")
    baseline = results['baseline_adam']
    fourier = results['hina_adaptive_fourier']

    psnr_improvement = fourier['psnr'] - baseline['psnr']
    hf_improvement = (fourier['hf_preservation'] - baseline['hf_preservation']) / baseline['hf_preservation'] * 100

    print(f"   PSNR æ”¹å–„: {psnr_improvement:+.2f}dB")
    print(f"   é«˜é »ä¿æŒæ”¹å–„: {hf_improvement:+.1f}%")

    if psnr_improvement > 0:
        print("   âœ… å‚…ç«‹è‘‰ç‰¹å¾µæå¤±å„ªåŒ–å™¨è¡¨ç¾æ›´å¥½ï¼")
    else:
        print("   âš ï¸  éœ€è¦èª¿æ•´åƒæ•¸ä»¥ç²å¾—æ›´å¥½æ•ˆæœ")

def visualize_frequency_analysis():
    """
    å¯è¦–åŒ–é »ç‡åˆ†æéç¨‹
    """
    print(f"\nğŸ” å‚…ç«‹è‘‰é »ç‡åˆ†æå¯è¦–åŒ–")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # å‰µå»ºæ¸¬è©¦åœ–åƒ
    lr_images, hr_images = create_synthetic_data(batch_size=1, lr_size=64, scale=4)

    # å‰µå»ºå¸¶æœ‰å‚…ç«‹è‘‰ç‰¹å¾µçš„å„ªåŒ–å™¨
    model = SuperResolutionModel(scale_factor=4).to(device)
    optimizer = HinaAdaptive(
        model.parameters(),
        fourier_feature_loss=True,
        super_resolution_mode=True,
        super_resolution_scale=4
    )

    # é€²è¡Œä¸€æ¬¡å‰å‘å’Œåå‘å‚³æ’­
    model.train()
    sr_images = model(lr_images)
    loss = F.mse_loss(sr_images, hr_images)

    optimizer.zero_grad()
    loss.backward()

    # åˆ†æç¬¬ä¸€å€‹å·ç©å±¤çš„æ¢¯åº¦
    first_conv = None
    for name, module in model.named_modules():
        if isinstance(module, nn.Conv2d):
            first_conv = module
            break

    if first_conv is not None and first_conv.weight.grad is not None:
        grad = first_conv.weight.grad[0, 0]  # å–ç¬¬ä¸€å€‹é€šé“çš„æ¢¯åº¦

        # è¨ˆç®—å‚…ç«‹è‘‰è®Šæ›
        grad_fft = torch.fft.fft2(grad)
        magnitude = torch.abs(grad_fft)

        # åˆ†æé »ç‡åˆ†ä½ˆ
        h, w = grad.shape
        freq_y = torch.fft.fftfreq(h, device=device).unsqueeze(1)
        freq_x = torch.fft.fftfreq(w, device=device).unsqueeze(0)
        freq_radius = torch.sqrt(freq_y**2 + freq_x**2)

        # è¨ˆç®—ä¸åŒé »æ®µçš„èƒ½é‡
        low_freq_mask = freq_radius <= 0.1
        mid_freq_mask = (freq_radius > 0.1) & (freq_radius <= 0.3)
        high_freq_mask = freq_radius > 0.3

        low_energy = torch.sum(magnitude * low_freq_mask.float()).item()
        mid_energy = torch.sum(magnitude * mid_freq_mask.float()).item()
        high_energy = torch.sum(magnitude * high_freq_mask.float()).item()

        total_energy = low_energy + mid_energy + high_energy

        print(f"é »ç‡èƒ½é‡åˆ†ä½ˆ:")
        print(f"   ä½é » (â‰¤0.1): {low_energy/total_energy*100:.1f}%")
        print(f"   ä¸­é » (0.1-0.3): {mid_energy/total_energy*100:.1f}%")
        print(f"   é«˜é » (>0.3): {high_energy/total_energy*100:.1f}%")

        # æ¨¡ç³ŠæŒ‡æ¨™
        blur_indicator = low_energy / (high_energy + 1e-8)
        print(f"   æ¨¡ç³ŠæŒ‡æ¨™: {blur_indicator:.2f} {'(åæ¨¡ç³Š)' if blur_indicator > 2.0 else '(æ­£å¸¸)'}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¨ å‚…ç«‹è‘‰ç‰¹å¾µæå¤±è¶…è§£æåº¦å„ªåŒ–æ¼”ç¤º")
    print("=" * 60)

    try:
        # 1. åŸºæœ¬è¨“ç·´æ¼”ç¤º
        print("ğŸ“ 1. åŸºæœ¬è¨“ç·´æ¼”ç¤º (4x è¶…è§£æåº¦)")
        train_with_fourier_loss(scale_factor=4)

        # 2. ä¸åŒæ”¾å¤§å€æ•¸æ¯”è¼ƒ
        print("\nğŸ“ 2. ä¸åŒæ”¾å¤§å€æ•¸æ¯”è¼ƒ")
        for scale in [2, 4, 8]:
            print(f"\n--- {scale}x è¶…è§£æåº¦ ---")
            history, _ = train_with_fourier_loss(scale_factor=scale)
            final_psnr = history['psnr'][-1] if history['psnr'] else 0
            print(f"{scale}x æœ€çµ‚ PSNR: {final_psnr:.2f}dB")

        # 3. èˆ‡åŸºæº–æ¯”è¼ƒ
        print("\nğŸ“ 3. èˆ‡åŸºæº–å„ªåŒ–å™¨æ¯”è¼ƒ")
        compare_with_baseline(scale_factor=4)

        # 4. é »ç‡åˆ†æå¯è¦–åŒ–
        print("\nğŸ“ 4. é »ç‡åˆ†æå¯è¦–åŒ–")
        visualize_frequency_analysis()

        print("\nâœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè­°:")
        print("   - å°æ–¼ 2x è¶…è§£æåº¦ï¼šä½¿ç”¨è¼ƒæº«å’Œçš„åƒæ•¸")
        print("   - å°æ–¼ 4x è¶…è§£æåº¦ï¼šå¹³è¡¡ç´°ç¯€ä¿æŒå’Œç©©å®šæ€§")
        print("   - å°æ–¼ 8x+ è¶…è§£æåº¦ï¼šåŠ å¼·é«˜é »ä¿æŒå’Œæ¨¡ç³ŠæŠ‘åˆ¶")
        print("   - æ ¹æ“š VRAM é™åˆ¶èª¿æ•´ memory_efficient å’Œ vram_budget_gb")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # æ¸…ç†è³‡æº
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

if __name__ == "__main__":
    main()